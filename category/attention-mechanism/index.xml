<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Attention Mechanism | Biswajit Sahoo</title>
    <link>https://biswajitsahoo1111.github.io/category/attention-mechanism/</link>
      <atom:link href="https://biswajitsahoo1111.github.io/category/attention-mechanism/index.xml" rel="self" type="application/rss+xml" />
    <description>Attention Mechanism</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2022 Biswajit Sahoo</copyright><lastBuildDate>Thu, 01 Apr 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://biswajitsahoo1111.github.io/media/icon_hu9aa3fb3801987e3e09a10d02b6e0c908_114644_512x512_fill_lanczos_center_3.png</url>
      <title>Attention Mechanism</title>
      <link>https://biswajitsahoo1111.github.io/category/attention-mechanism/</link>
    </image>
    
    <item>
      <title>IndexedSlices in Tensorflow</title>
      <link>https://biswajitsahoo1111.github.io/post/indexedslices-in-tensorflow/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://biswajitsahoo1111.github.io/post/indexedslices-in-tensorflow/</guid>
      <description>
&lt;script src=&#34;https://biswajitsahoo1111.github.io/post/indexedslices-in-tensorflow/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;table class=&#34;tfo-notebook-buttons&#34; align=&#34;left&#34;&gt;
&lt;td&gt;
&lt;a href=&#34;https://colab.research.google.com/github/biswajitsahoo1111/blog_notebooks/blob/master/Tensorflow_IndexedSlices.ipynb&#34;&gt;
&lt;img src=&#34;https://www.tensorflow.org/images/colab_logo_32px.png&#34; /&gt;
Run in Google Colab&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://github.com/biswajitsahoo1111/blog_notebooks/blob/master/Tensorflow_IndexedSlices.ipynb&#34;&gt;
&lt;img src=&#34;https://www.tensorflow.org/images/GitHub-Mark-32px.png&#34; /&gt;
View source on GitHub&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;
&lt;a href=&#34;https://www.dropbox.com/s/paze6mubda9bvv4/Tensorflow_IndexedSlices.ipynb?dl=1&#34;&gt;&lt;img src=&#34;https://www.tensorflow.org/images/download_logo_32px.png&#34; /&gt;Download notebook&lt;/a&gt;
&lt;/td&gt;
&lt;/table&gt;
&lt;p&gt;In this post, we will discuss about &lt;code&gt;IndexedSlices&lt;/code&gt; class of &lt;code&gt;Tensorflow&lt;/code&gt;. We will try to answer the following questions in this blog:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#q1&#34;&gt;What are &lt;code&gt;IndexedSlices&lt;/code&gt;?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#q2&#34;&gt;Where do we get it?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#q3&#34;&gt;How to convert from IndexedSlices to tensors?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id = &#34;q1&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;what-are-indexedslices&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What are &lt;code&gt;IndexedSlices&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;According to &lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/IndexedSlices&#34;&gt;&lt;code&gt;Tensorflow&lt;/code&gt; documentation&lt;/a&gt;, &lt;code&gt;IndexedSlices&lt;/code&gt; are sparse representation of a set of tensor slices at a given index. At an high level it appears to be some kind of sparse representation. Let’s try to understand it with examples.&lt;/p&gt;
&lt;p&gt;&lt;a id = &#34;q2&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;where-do-we-get-it&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Where do we get it?&lt;/h2&gt;
&lt;p&gt;We get &lt;code&gt;IndexedSlices&lt;/code&gt; while taking gradients of an &lt;code&gt;Embedding&lt;/code&gt; layer. Embedding matrices can be huge (depending on vocabulary size). But each batch only contains a small fraction of tokens. So while computing the gradient of loss with respect to embedding layer, in each pass we have to only consider the corresponding token embeedings of the present batch. Naturally a sparse tensor seems to be a better option to record those gradients. &lt;code&gt;Tensorflow&lt;/code&gt; does that using &lt;code&gt;IndexedSlices&lt;/code&gt;. We will show that below using a contrived example.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import tensorflow as tf
print(&amp;quot;Tensorflow version: &amp;quot;, tf.__version__)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Tensorflow version:  2.4.0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;model = tf.keras.models.Sequential([
    # Vocab size: 10, Embedding dimension: 4, Input_shape size: (batch_size, num_words). As usual, batch_size is omitted.
    tf.keras.layers.Embedding(10, 4, input_shape = (5,)),
    tf.keras.layers.Flatten(), 
    tf.keras.layers.Dense(1)
])
model.summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 5, 4)              40        
_________________________________________________________________
flatten (Flatten)            (None, 20)                0         
_________________________________________________________________
dense (Dense)                (None, 1)                 21        
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data = tf.random.uniform(shape = (1, 5), minval = 0, maxval = 10, dtype = tf.int32) # Batch size is 1.
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[6, 1, 1, 4, 8]])&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;model.variables  # Is a list of 3 tensors. 1 from Embedding layer and 2 from Dense layer (Kernel and bias)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[&amp;lt;tf.Variable &amp;#39;embedding/embeddings:0&amp;#39; shape=(10, 4) dtype=float32, numpy=
 array([[ 4.10897247e-02, -2.48962641e-03,  1.26880072e-02,
          3.39310430e-02],
        [ 3.28579657e-02,  3.90318781e-03,  2.81411521e-02,
          3.09719704e-02],
        [ 1.16247907e-02, -1.41257644e-02, -3.36343870e-02,
         -4.41543460e-02],
        [-4.67238426e-02,  2.42819674e-02, -4.26802635e-02,
         -2.59207971e-02],
        [ 2.28367783e-02, -2.09717881e-02,  1.05572566e-02,
          3.33249308e-02],
        [-3.37148309e-02, -4.61939685e-02, -2.61853095e-02,
         -4.10162285e-03],
        [-3.59787717e-02,  2.78765075e-02, -3.16200405e-02,
          4.54976298e-02],
        [-4.67344411e-02, -1.30221620e-02,  1.52915232e-02,
          2.22466923e-02],
        [-1.03901625e-02,  2.40740217e-02, -1.24427900e-02,
          4.47194651e-03],
        [-3.57637033e-02,  4.28059734e-02, -2.59280205e-05,
          4.09286283e-02]], dtype=float32)&amp;gt;,
 &amp;lt;tf.Variable &amp;#39;dense/kernel:0&amp;#39; shape=(20, 1) dtype=float32, numpy=
 array([[ 0.42870212],
        [ 0.04779923],
        [ 0.4126016 ],
        [-0.13294601],
        [-0.3175783 ],
        [-0.46080017],
        [-0.23412797],
        [ 0.30137837],
        [-0.5197849 ],
        [-0.10935467],
        [ 0.5087845 ],
        [-0.06930307],
        [ 0.10028934],
        [-0.11278141],
        [-0.21269777],
        [-0.0214209 ],
        [ 0.12959635],
        [-0.13330323],
        [-0.23972857],
        [ 0.23718971]], dtype=float32)&amp;gt;,
 &amp;lt;tf.Variable &amp;#39;dense/bias:0&amp;#39; shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&amp;gt;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;optimizer = tf.keras.optimizers.SGD(learning_rate = 0.1)
loss_object = tf.keras.losses.MeanSquaredError()
target = tf.constant([2.5], shape = (1,1))
for _ in range(2):   # Let&amp;#39;s run gradient descent for two batches of the same input data. (It&amp;#39;s a contrived examples)
    with tf.GradientTape() as tape:
        output = model(data) # Output has shape: (batch_size, 1). Here batch_size is 1. So output shape is (1,1)
        loss_value = loss_object(target, output)  # Calculating some random loss.
    grads = tape.gradient(loss_value, model.trainable_variables)

    # Gradient descent step
    optimizer.apply_gradients(zip(grads, model.trainable_variables))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;len(grads)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;grads[0]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;tensorflow.python.framework.indexed_slices.IndexedSlices at 0x16c04d4a970&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;print(grads[0])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;IndexedSlices(indices=tf.Tensor([6 1 1 4 8], shape=(5,), dtype=int32), values=tf.Tensor(
[[-0.9495101  -0.14344962 -0.91739434  0.25398374]
 [ 0.69607455  1.0615798   0.5085497  -0.7338184 ]
 [ 1.1639317   0.24842012 -1.2103697   0.12384857]
 [-0.25895947  0.2856651   0.47968888  0.01028775]
 [-0.28760925  0.28005898  0.56933826 -0.5540699 ]], shape=(5, 4), dtype=float32), dense_shape=tf.Tensor([10  4], shape=(2,), dtype=int32))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An &lt;code&gt;IndexedSlices&lt;/code&gt; object has 3 main entries.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;indices&lt;/li&gt;
&lt;li&gt;values, and&lt;/li&gt;
&lt;li&gt;dense_shape&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id = &#34;q3&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-convert-indexedslices-to-tensors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How to convert &lt;code&gt;IndexedSlices&lt;/code&gt; to &lt;code&gt;Tensors&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;Before we do the conversion, let’s answer a relevant question: Why do we have to do the conversion from &lt;code&gt;IndexedSlices&lt;/code&gt; to tensors given that &lt;code&gt;Tensorflow&lt;/code&gt; can do a gradient descent step automatically through the &lt;code&gt;IndexedSlices&lt;/code&gt;? In the last section, we could run 2 gradient descent steps without worrying about &lt;code&gt;IndexedSlices&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But the problem occurs if we want to do some processing on gradient values. One such processing is &lt;code&gt;gradient clipping&lt;/code&gt;. In &lt;code&gt;gradient clipping&lt;/code&gt;, if sum of norm of gradients exceed a given value, gradients are rescaled to decrease their magnitude. Therefore, to do any gradient clipping, we have to access the gradient tensors. This is precisely where we would like to convert IndexedSlices to tensors. Having an embedding layer is common in deep learning models and applying gradient clipping to gradient values is also a common practice. We will show two approaches to do the conversion.&lt;/p&gt;
&lt;div id=&#34;easiest-approach&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Easiest approach&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;tf.convert_to_tensor(grads[0])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(10, 4), dtype=float32, numpy=
array([[ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 1.8600063 ,  1.31      , -0.70182   , -0.60996985],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.25895947,  0.2856651 ,  0.47968888,  0.01028775],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.9495101 , -0.14344962, -0.91739434,  0.25398374],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.28760925,  0.28005898,  0.56933826, -0.5540699 ],
       [ 0.        ,  0.        ,  0.        ,  0.        ]],
      dtype=float32)&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;what-did-just-happen-in-the-last-step&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;What did just happen in the last step?&lt;/h3&gt;
&lt;p&gt;Though the last approach is a single line elegant solution, it hides many things. How actually is the conversion done? The code below shows the steps in which we can manually do the conversion.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;check_grad = tf.zeros_like(model.variables[0]).numpy()   # Create a dense tensor of all zeros
for i, ind in enumerate(grads[0].indices):
    check_grad[ind] = check_grad[ind] + grads[0].values[i]
check_grad&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;array([[ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 1.8600063 ,  1.31      , -0.70182   , -0.60996985],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.25895947,  0.2856651 ,  0.47968888,  0.01028775],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.9495101 , -0.14344962, -0.91739434,  0.25398374],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.28760925,  0.28005898,  0.56933826, -0.5540699 ],
       [ 0.        ,  0.        ,  0.        ,  0.        ]],
      dtype=float32)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This brings us to the end of this blog. I hope this blog has demystified a few things about &lt;code&gt;IndexedSlices&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Motivation for this post&lt;/strong&gt;: While writing TF 2 code for &lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF&#34;&gt;Attention Mechanisms chapter of D2L book&lt;/a&gt;, the author encountered an error involving &lt;code&gt;IndexedSlices&lt;/code&gt;. After spending a good deal of time hopelessly trying to figure out what’s going on, the author finally found that the error was occurring because of an user defined gradient clipping function that didn’t handle &lt;code&gt;IndexedSlices&lt;/code&gt; properly. The model involved embedding layers as it was dealing with machine translation task. Therefore, I thought of writing this blog with the hope that it would be of help to readers who are struggling to figure out what &lt;code&gt;IndexedSlices&lt;/code&gt; are.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2 code for Attention Mechanisms chapter of Dive into Deep Learning (D2L) book</title>
      <link>https://biswajitsahoo1111.github.io/post/tensorflow-2-code-for-attention-mechanisms-chapter-of-d2l-book/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://biswajitsahoo1111.github.io/post/tensorflow-2-code-for-attention-mechanisms-chapter-of-d2l-book/</guid>
      <description>
&lt;script src=&#34;https://biswajitsahoo1111.github.io/post/tensorflow-2-code-for-attention-mechanisms-chapter-of-d2l-book/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;table class=&#34;tfo-notebook-buttons&#34; align=&#34;left&#34;&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;
&lt;iframe src=&#34;https://ghbtns.com/github-btn.html?user=biswajitsahoo1111&amp;amp;repo=D2L_Attention_Mechanisms_in_TF&amp;amp;type=star&amp;amp;count=true&amp;amp;size=large&#34; frameborder=&#34;0&#34; scrolling=&#34;0&#34; width=&#34;170&#34; height=&#34;30&#34; title=&#34;GitHub&#34;&gt;
&lt;/iframe&gt;
&lt;/td&gt;
&lt;!-----
  &lt;td align=&#34;left&#34; rowspan=&#34;2&#34;&gt;
    &lt;a href=&#34;https://biswajitsahoo1111.github.io/rul_codes_open/&#34;&gt;&lt;img src=&#34;https://www.tensorflow.org/images/GitHub-Mark-32px.png&#34; /&gt;View GitHub Page&lt;/a&gt;
  &lt;/td&gt;
  -----&gt;
&lt;td align=&#34;left&#34; rowspan=&#34;2&#34;&gt;
&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF&#34;&gt;&lt;img src=&#34;https://www.tensorflow.org/images/GitHub-Mark-32px.png&#34; /&gt;View source on GitHub&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&#34;left&#34; rowspan=&#34;2&#34;&gt;
&lt;a href=&#34;https://codeload.github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/zip/master&#34;&gt;&lt;img src=&#34;https://www.tensorflow.org/images/download_logo_32px.png&#34; /&gt;Download code (.zip)&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;
&lt;iframe src=&#34;https://ghbtns.com/github-btn.html?user=biswajitsahoo1111&amp;amp;repo=D2L_Attention_Mechanisms_in_TF&amp;amp;type=fork&amp;amp;count=true&amp;amp;size=small&#34; frameborder=&#34;0&#34; scrolling=&#34;0&#34; width=&#34;170&#34; height=&#34;30&#34; title=&#34;GitHub&#34; margin-left=&#34;auto&#34; margin-right=&#34;auto&#34;&gt;
&lt;/iframe&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;span style=&#34;color: purple;&#34;&gt;&lt;strong&gt;This code has been merged with D2L book. See PR: &lt;a href=&#34;https://github.com/d2l-ai/d2l-en/pull/1756&#34;&gt;1756&lt;/a&gt;, &lt;a href=&#34;https://github.com/d2l-ai/d2l-en/pull/1768&#34;&gt;1768&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This post contains &lt;code&gt;Tensorflow 2&lt;/code&gt; code for Attention Mechanisms chapter of &lt;a href=&#34;http://d2l.ai/&#34;&gt;Dive into Deep Learning (D2L)&lt;/a&gt; book. The chapter has 7 sections and code for each section can be found at the following links. We have given only code implementations. For theory, readers should refer the book.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_1_Visualization_of_attention.ipynb&#34;&gt;10.1. Attention Cues&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_2_Attention_based_regression.ipynb&#34;&gt;10.2. Attention Pooling: Nadaraya-Watson Kernel Regression&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_3_Attention_scoring_functions.ipynb&#34;&gt;10.3. Attention Scoring Functions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_4_Bahdanau_attention.ipynb&#34;&gt;10.4. Bahdanau Attention&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_5_Multi-head_attention.ipynb&#34;&gt;10.5. Multi-Head Attention&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_6_Self-attention_and_positional_encoding.ipynb&#34;&gt;10.6. Self-Attention and Positional Encoding&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_7_Transformer.ipynb&#34;&gt;10.7. Transformer&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;additional-sections&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Additional sections:&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/additional_sections/9_7_Sequence_to_Sequence_Learning.ipynb&#34;&gt;9.7. Sequence to Sequence Learning&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-chapters&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Additional Chapters:&lt;/h3&gt;
&lt;p&gt;Chapter 17: &lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Generative_Adversarial_Networks_in_TF&#34;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-to-run-these-code&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How to run these code:&lt;/h3&gt;
&lt;p&gt;The best way (in our opinion) is to either clone the repo (or download the zipped repo) and then run each notebook from the cloned (or extracted) folder. All the notebooks will run without any issue.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: We claim no originality for the code. Credit goes to the authors of this excellent &lt;a href=&#34;http://d2l.ai/&#34;&gt;book&lt;/a&gt;. However, all errors and omissions are my own and readers are encouraged to bring it to my notice. Finally, no TF code was available (to the best of my knowledge) for &lt;code&gt;Attention Mechanisms&lt;/code&gt; chapter when &lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF&#34;&gt;this repo&lt;/a&gt; was first made public.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>

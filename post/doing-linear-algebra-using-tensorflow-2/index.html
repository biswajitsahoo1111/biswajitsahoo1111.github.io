<!doctype html>
<!-- This site was created with Hugo Blox. https://hugoblox.com -->
<!-- Last Published: December 28, 2024 --><html lang="en-us" dir="ltr"
      data-wc-theme-default="system">
  
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="generator" content="Hugo Blox Builder 0.3.1" />

  
  












  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Biswajit Sahoo" />

  
  
  
    
  
  <meta name="description" content="Perform linear algebraic operations only using Tensorflow." />

  
  <link rel="alternate" hreflang="en-us" href="http://localhost:1313/post/doing-linear-algebra-using-tensorflow-2/" />

  
  
  
  
    
    <link rel="stylesheet" href="/css/themes/emerald.min.css" />
  

  
  
    
    <link href="/dist/wc.min.css" rel="stylesheet" />
  

  
  
  

  

  <script>
     
    window.hbb = {
       defaultTheme: document.documentElement.dataset.wcThemeDefault,
       setDarkTheme: () => {
        document.documentElement.classList.add("dark");
        document.documentElement.style.colorScheme = "dark";
      },
       setLightTheme: () => {
        document.documentElement.classList.remove("dark");
        document.documentElement.style.colorScheme = "light";
      }
    }

    console.debug(`Default Hugo Blox Builder theme is ${window.hbb.defaultTheme}`);

    if ("wc-color-theme" in localStorage) {
      localStorage.getItem("wc-color-theme") === "dark" ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
    } else {
      window.hbb.defaultTheme === "dark" ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
      if (window.hbb.defaultTheme === "system") {
        window.matchMedia("(prefers-color-scheme: dark)").matches ? window.hbb.setDarkTheme() : window.hbb.setLightTheme();
      }
    }
  </script>

  <script>
    
    document.addEventListener('DOMContentLoaded', function () {
      
      let checkboxes = document.querySelectorAll('li input[type=\'checkbox\'][disabled]');
      checkboxes.forEach(e => {
        e.parentElement.parentElement.classList.add('task-list');
      });

      
      const liNodes = document.querySelectorAll('.task-list li');
      liNodes.forEach(nodes => {
        let textNodes = Array.from(nodes.childNodes).filter(node => node.nodeType === 3 && node.textContent.trim().length > 1);
        if (textNodes.length > 0) {
          const span = document.createElement('label');
          textNodes[0].after(span);  
          span.appendChild(nodes.querySelector('input[type=\'checkbox\']'));
          span.appendChild(textNodes[0]);
        }
      });
    });
  </script>

  
  
  




































  
  

  
  <link rel="icon" type="image/png" href="/media/icon_hu15771692248986819267.png" />
  <link rel="apple-touch-icon" type="image/png" href="/media/icon_hu13363495885888113771.png" />

  <link rel="canonical" href="http://localhost:1313/post/doing-linear-algebra-using-tensorflow-2/" />

  
  
  
  
  
  
  
  
    
    
  
  

  
  
    
    
  
  <meta property="twitter:card" content="summary" />
  
  <meta property="og:site_name" content="Biswajit Sahoo" />
  <meta property="og:url" content="http://localhost:1313/post/doing-linear-algebra-using-tensorflow-2/" />
  <meta property="og:title" content="Doing Linear Algebra using Tensorflow 2 | Biswajit Sahoo" />
  <meta property="og:description" content="Perform linear algebraic operations only using Tensorflow." /><meta property="og:image" content="http://localhost:1313/media/icon_hu14255546723713444625.png" />
    <meta property="twitter:image" content="http://localhost:1313/media/icon_hu14255546723713444625.png" /><meta property="og:locale" content="en-us" />
  
    
      <meta
        property="article:published_time"
        content="2020-05-14T00:00:00&#43;00:00"
      />
    
    <meta property="article:modified_time" content="2020-05-14T00:00:00&#43;00:00">
  

  



  


  <title>Doing Linear Algebra using Tensorflow 2 | Biswajit Sahoo</title>

  
  
  
  
  
    
    
  
  
  <style>
    @font-face {
      font-family: 'Inter var';
      font-style: normal;
      font-weight: 100 900;
      font-display: swap;
      src: url(/dist/font/Inter.var.woff2) format(woff2);
    }
  </style>

  

  
  


  
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
      
      
        
        
          
        
          
        
          
        
          
        
          
        
        
        
      
    
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  







<link type="text/css" rel="stylesheet" href="/dist/pagefind/pagefind-ui.be766eb419317a14ec769d216e9779bfe8f3737c80e780f4ba0dafb57a41a482.css" integrity="sha256-vnZutBkxehTsdp0hbpd5v&#43;jzc3yA54D0ug2vtXpBpII=" />


<script src="/dist/pagefind/pagefind-ui.87693d7c6f2b3b347ce359d0ede762c033419f0a32b22ce508c335a81d841f1b.js" integrity="sha256-h2k9fG8rOzR841nQ7ediwDNBnwoysizlCMM1qB2EHxs="></script>


<script>window.hbb.pagefind = {"baseUrl":"/"};</script>

<style>
  html.dark {
    --pagefind-ui-primary: #eeeeee;
    --pagefind-ui-text: #eeeeee;
    --pagefind-ui-background: #152028;
    --pagefind-ui-border: #152028;
    --pagefind-ui-tag: #152028;
  }
</style>

<script>
  window.addEventListener('DOMContentLoaded', (event) => {
    new PagefindUI({
      element: "#search",
      showSubResults: true,
      baseUrl: window.hbb.pagefind.baseUrl,
      bundlePath: window.hbb.pagefind.baseUrl + "pagefind/",
    });
  });
  document.addEventListener('DOMContentLoaded', () => {
    let element = document.getElementById('search');
    let trigger = document.getElementById('search_toggle');

    if (trigger) {
      trigger.addEventListener('click', () => {
        element.classList.toggle('hidden');
        element.querySelector("input").value = ""
        element.querySelector("input").focus()

        if (!element.classList.contains('hidden')) {
          let clear_trigger = document.querySelector('.pagefind-ui__search-clear');

          if (clear_trigger && !clear_trigger.hasAttribute('listenerOnClick')) {
            clear_trigger.setAttribute('listenerOnClick', 'true');

            clear_trigger.addEventListener('click', () => {
              element.classList.toggle('hidden');
            });
          }
        }

      });
    }
  });
</script>










  
  
  <link type="text/css" rel="stylesheet" href="/dist/lib/katex/katex.min.505d5f829022bb7b4f24dfee0aa1141cd7bba67afe411d1240335f820960b5c3.css" integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr&#43;QR0SQDNfgglgtcM=" />
  
  
  <script defer src="/dist/lib/katex/katex.min.dc84b296ec3e884de093158f760fd9d45b6c7abe58b5381557f4e138f46a58ae.js" integrity="sha256-3ISyluw&#43;iE3gkxWPdg/Z1Ftser5YtTgVV/ThOPRqWK4="></script>
  
  
  
  
  <script defer src="/js/katex-renderer.6579ec9683211cfb952064aedf3a3baea5eeb17a061775b32b70917474637c80.js" integrity="sha256-ZXnsloMhHPuVIGSu3zo7rqXusXoGF3WzK3CRdHRjfIA="></script>
  
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  






  
  
  
  
  
  
  
  <script
    defer
    src="/js/hugo-blox-en.min.js"
    integrity=""
  ></script>

  
  








  
    
      
      <script async defer src="https://buttons.github.io/buttons.js"></script>

      
    
  




</head>

  <body class="dark:bg-hb-dark dark:text-white page-wrapper" id="top">
    <div id="page-bg"></div>
    <div class="page-header sticky top-0 z-30">
      
      
      
        
        
        
          <header id="site-header" class="header">
  <nav class="navbar px-3 flex justify-left">
    <div class="order-0 h-100">
      
      <a class="navbar-brand" href="/" title="Biswajit Sahoo">
        Biswajit Sahoo
      </a>
    </div>
    
    <input id="nav-toggle" type="checkbox" class="hidden" />
    <label
      for="nav-toggle"
      class="order-3 cursor-pointer flex items-center lg:hidden text-dark dark:text-white lg:order-1">
      <svg id="show-button" class="h-6 fill-current block" viewBox="0 0 20 20">
        <title>Open Menu</title>
        <path d="M0 3h20v2H0V3z m0 6h20v2H0V9z m0 6h20v2H0V0z"></path>
      </svg>
      <svg id="hide-button" class="h-6 fill-current hidden" viewBox="0 0 20 20">
        <title>Close Menu</title>
        <polygon
          points="11 9 22 9 22 11 11 11 11 22 9 22 9 11 -2 11 -2 9 9 9 9 -2 11 -2"
          transform="rotate(45 10 10)"></polygon>
      </svg>
    </label>
    

    
    
    <ul
      id="nav-menu"
      class="navbar-nav order-3 hidden lg:flex w-full pb-6 lg:order-1 lg:w-auto lg:space-x-2 lg:pb-0 xl:space-x-8 justify-left
      ml-auto mr-6">
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/"
        >Home</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/#blog"
        >Blog</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/#projects"
        >Projects</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/#experience"
        >Experience</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/#publications"
        >Publications</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/personal/"
        >Personal</a
        >
      </li>
      
      
      
      
      
      
      <li class="nav-item">
        <a
          class="nav-link "
          
          href="/#contact"
        >Contact</a
        >
      </li>
      
      
      
    </ul>

    <div class="order-1 ml-auto flex items-center md:order-2 lg:ml-0">

      
      
      
      <button
        aria-label="search"
        class="text-black hover:text-primary  inline-block px-3 text-xl dark:text-white"
        id="search_toggle">
        <svg xmlns="http://www.w3.org/2000/svg" height="16" width="16" viewBox="0 0 512 512" fill="currentColor"><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352a144 144 0 1 0 0-288 144 144 0 1 0 0 288z"/></svg>
      </button>
      

      
      
      <div class="px-3 text-black hover:text-primary-700 dark:text-white dark:hover:text-primary-300
            [&.active]:font-bold [&.active]:text-black/90 dark:[&.active]:text-white">
        <button class="theme-toggle mt-1" accesskey="t" title="appearance">
          <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round" class="dark:hidden">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
          </svg>
          <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
               fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
               stroke-linejoin="round" class=" dark:block [&:not(dark)]:hidden">
            <circle cx="12" cy="12" r="5"></circle>
            <line x1="12" y1="1" x2="12" y2="3"></line>
            <line x1="12" y1="21" x2="12" y2="23"></line>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
            <line x1="1" y1="12" x2="3" y2="12"></line>
            <line x1="21" y1="12" x2="23" y2="12"></line>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
          </svg>
        </button>
      </div>
      

      
      

      
      
    </div>
  </nav>
</header>


<div id="search" class="hidden p-3"></div>


        
      
    </div>
    <div class="page-body  my-10">
      





<div class="mx-auto flex max-w-screen-xl">
  



<aside class="hb-sidebar-container max-lg:[transform:translate3d(0,-100%,0)] lg:hidden xl:block">
  
  <div class="px-4 pt-4 lg:hidden">
    
    
  </div>
  <div class="hb-scrollbar lg:h-[calc(100vh-var(--navbar-height))]">
    <ul class="flex flex-col gap-1 lg:hidden">
      
      
        <li class="open"><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/"
    
  >Blog
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/compute-element-stiffness-matrix-symbolically/"
    
  >Compute element stiffness matrix symbolically
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/making-github-traffic-type-plots/"
    
  >Making Github Traffic Type Plots
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/indexdslices-in-tensorflow/"
    
  >IndexedSlices in Tensorflow
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/tensorflow-2-code-for-attention-mechanisms-chapter-of-d2l-book/"
    
  >Tensorflow 2 code for Attention Mechanisms chapter of Dive into Deep Learning (D2L) book
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/reading-multiple-files-in-tensorflow-2-using-sequence/"
    
  >Reading multiple files in Tensorflow 2 using Sequence
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/reading-multiple-csv-files-in-pytorch/"
    
  >Reading multiple csv files in PyTorch
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/efficiently-reading-multiple-files-in-tensorflow-2/"
    
  >Efficiently reading multiple files in Tensorflow 2
    </a>
              
            </li><li class="flex flex-col open"><a
    class="hb-sidebar-custom-link
      sidebar-active-item bg-primary-100 font-semibold text-primary-800 dark:bg-primary-300 dark:text-primary-900"
    href="/post/doing-linear-algebra-using-tensorflow-2/"
    
  >Doing Linear Algebra using Tensorflow 2
    </a>
  
    <ul class="hb-sidebar-mobile-toc"><li>
              <a
                href="#basics"
                class="hb-docs-link"
              >Basics</a>
            </li>
          <li>
              <a
                href="#matrix-factorizations"
                class="hb-docs-link"
              >Matrix factorizations</a>
            </li>
          <li>
              <a
                href="#eigenvalues-and-eigenvectors"
                class="hb-docs-link"
              >Eigenvalues and eigenvectors</a>
            </li>
          <li>
              <a
                href="#solving-dense-linear-systems"
                class="hb-docs-link"
              >Solving dense linear systems</a>
            </li>
          <li>
              <a
                href="#solving-structured-linear-systems"
                class="hb-docs-link"
              >Solving structured linear systems</a>
            </li>
          <li>
              <a
                href="#solving-triangular-systems"
                class="hb-docs-link"
              >Solving triangular systems</a>
            </li>
          <li>
              <a
                href="#solving-least-squares-problems"
                class="hb-docs-link"
              >Solving least squares problems</a>
            </li>
          <li>
              <a
                href="#some-specialized-operations"
                class="hb-docs-link"
              >Some specialized operations</a>
            </li>
          <li>
              <a
                href="#linear-operators"
                class="hb-docs-link"
              >Linear operators</a>
            </li>
          <li>
              <a
                href="#conclusion"
                class="hb-docs-link"
              >Conclusion</a>
            </li>
          <li>
              <a
                href="#references"
                class="hb-docs-link"
              >References</a>
            </li>
          </ul>
  
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/reading-multiple-files-in-tensorflow-2/"
    
  >Reading multiple files in Tensorflow 2
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/using-python-generators/"
    
  >Using Python Generators
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/fault-diagnosis-of-machines/"
    
  >Fault Diagnosis of Machines
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/revisiting-systems-of-linear-equations/"
    
  >Revisiting Systems of Linear Equations
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/principal-component-analysis-part-iii/"
    
  >Principal Component Analysis - Part III
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/principal-component-analysis-part-ii/"
    
  >Principal Component Analysis - Part II
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/post/principal-component-analysis-part-i/"
    
  >Principal Component Analysis - Part I
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/"
    
  >Publications
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/data_driven_features_fault_diagnosis/"
    
  >Multiclass bearing fault classification using features learned by a deep neural network
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/ml_regression_optimization/"
    
  >Machine Learning, Regression, and Optimization
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/publication/spca_fault_diagnosis/"
    
  >Feature Subset Selection Using Sparse Principal Component Analysis and Multiclass Fault Classification Using Selected Features
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/"
    
  >Projects
        <span data-hb-sidebar-toggle>
            <svg fill="none" viewBox="0 0 24 24" stroke="currentColor" class="h-[18px] min-w-[18px] rounded-sm p-0.5 hover:bg-gray-800/5 dark:hover:bg-gray-100/5"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7" class="origin-center transition-transform rtl:-rotate-180"></path></svg>
        </span>
    </a><div class="ltr:pr-0 overflow-hidden">
        <ul class="hb-sidebar-list"><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/rul_codes_open/"
    
  >Data-Driven Remaining Useful Life (RUL) Prediction
    </a>
              
            </li><li class="flex flex-col "><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/project/cbm_codes_open/"
    
  >Data-Driven Machinery Fault Diagnosis
    </a>
              
            </li></ul>
      </div></li>
        <li class=""><a
    class="hb-sidebar-custom-link
      text-gray-500 hover:bg-gray-100 hover:text-gray-900 dark:text-gray-300 dark:hover:bg-primary-800 dark:hover:text-gray-50"
    href="/personal/"
    
  >
    </a></li>
    </ul>

    <div class="max-xl:hidden h-0 w-64 shrink-0"></div></div>

</aside>
  

<nav class="hb-toc order-last hidden w-64 shrink-0 xl:block print:hidden px-4" aria-label="table of contents">
  











  <div class="hb-scrollbar text-sm [hyphens:auto] sticky top-16 overflow-y-auto pr-4 pt-6 max-h-[calc(100vh-var(--navbar-height)-env(safe-area-inset-bottom))] -mr-4 rtl:-ml-4"><p class="mb-4 font-semibold tracking-tight">On this page</p><ul>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#basics">Basics</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#creating-tensors">Creating tensors</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#creating-a-sequence-of-numbers">Creating a sequence of numbers</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#slicing">Slicing</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#modifying-elements-of-a-matrix">Modifying elements of a matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#creating-a-complex-matrix">Creating a complex matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#transpose-of-a-matrix">Transpose of a matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#transpose-of-a-real-matrix">Transpose of a real matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#transpose-of-a-complex-matrix">Transpose of a complex matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#some-common-matrices">Some common matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#identity-matrix">Identity matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#diagonal-matrix">Diagonal matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#note-on-alignment-strategy">Note on alignment strategy</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#why-do-we-need-an-alignment-strategy">Why do we need an alignment strategy?</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#tri-diagonal-matrix">Tri-diagonal matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#tri-digonal-matrix-using-tflinalgset_diag">Tri-digonal matrix using tf.linalg.set_diag</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-of-all-zeros-and-ones">Matrix of all zeros and ones</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#random-matrices">Random matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-12 rtl:pr-12 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#random-uniform-matrix">Random uniform matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-12 rtl:pr-12 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#random-normal-matrix">Random normal matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-12 rtl:pr-12 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#truncated-random-normal-matrix">Truncated random normal matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-12 rtl:pr-12 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#random-poisson-matrix">Random Poisson matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-12 rtl:pr-12 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#random-gamma-matrix">Random gamma matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#some-special-matrices">Some special matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#sparse-matrices">Sparse matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-multiplication">Matrix multiplication</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#multiplying-two-column-vectors">Multiplying two column vectors</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-12 rtl:pr-12 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#inner-product">Inner product</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-12 rtl:pr-12 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#outer-product">Outer product</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#multiplying-a-matrix-with-a-vector">Multiplying a matrix with a vector</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#multiplying-two-matrices">Multiplying two matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#multiplying-two-tri-diagonal-matrices">Multiplying two tri-diagonal matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#how-to-multiply-two-tri-diagonal-matrices">How to multiply two tri-diagonal matrices?</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#some-common-operations-on-matrices">Some common operations on matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#trace">Trace</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#determinant">Determinant</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#rank">Rank</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-inverse">Matrix inverse</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#inverse-using-lu-factors">Inverse using  factors</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#extract-diagonals-of-a-matrix">Extract diagonals of a matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#extract-band-part-of-a-matrix">Extract band part of a matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-factorizations">Matrix factorizations</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#lu">LU</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#cholesky">Cholesky</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#qr">QR</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#svd">SVD</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#eigenvalues-and-eigenvectors">Eigenvalues and eigenvectors</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#eigen-analysis-of-hermitian-matrices">Eigen-analysis of Hermitian matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#what-happens-if-you-pass-a-nonsymmetric-matrix-to-eigh-by-mistake">What happens if you pass a nonsymmetric matrix to eigh by mistake?</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#eigen-analysis-of-non-hermitian-matrices">Eigen-analysis of non-Hermitian matrices</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#what-happens-when-you-pass-a-symmetric-matrix-to-eig">What happens when you pass a symmetric matrix to eig?</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#solving-dense-linear-systems">Solving dense linear systems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#using-lu-decomposition">Using LU decomposition</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#using-cholesky-decomposition">Using Cholesky decomposition</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#solving-structured-linear-systems">Solving structured linear systems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#solving-triangular-systems">Solving triangular systems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#solving-tri-diagonal-systems">Solving tri-diagonal systems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#solving-banded-triangular-systems">Solving banded triangular systems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#solving-least-squares-problems">Solving least squares problems</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#ordinary-least-squares">Ordinary least squares</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#regularized-least-squares">Regularized least squares</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#some-specialized-operations">Some specialized operations</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#norm">Norm</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#normalizing-a-tensor">Normalizing a tensor</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#global-norm">Global norm</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#cross-product-of-vectors">Cross product of vectors</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-square-root">Matrix square root</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-exponential">Matrix exponential</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-logarithm">Matrix logarithm</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#log-determinant-of-a-matrix">Log-determinant of a matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#pseudo-inverse-of-a-matrix">Pseudo inverse of a matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#linear-operators">Linear operators</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#common-methods-on-linear-operators">Common methods on linear operators</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#special-matrices-using-operators">Special matrices using operators</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#toeplitz-matrix">Toeplitz matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#circulant-matrix">Circulant matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#block-diagonal-matrix">Block diagonal matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#block-lower-triangular-matrix">Block lower triangular matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#householder-matrix">Householder matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#kronecker-matrix">Kronecker matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#permutation-matrix">Permutation matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#common-matrices-using-operators">Common matrices using operators</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#identity-matrix-1">Identity matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#scaled-identity-matrix">Scaled identity matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#diagonal-matrix-1">Diagonal matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#tri-diagonal-matrix-1">Tri-diagonal matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#lower-triangular-matrix">Lower triangular matrix</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-of-zeros">Matrix of zeros</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-4 rtl:pr-4 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#matrix-operations-using-operators">Matrix operations using operators</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#low-rank-update">Low-rank update</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#operator-inversion">Operator inversion</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="pl-8 rtl:pr-8 inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#operator-composition">Operator composition</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#conclusion">Conclusion</a>
      </li>
      <li class="my-2 scroll-my-6 scroll-py-6">
        <a class="font-semibold inline-block text-gray-500 hover:text-gray-900 dark:text-gray-400 dark:hover:text-gray-300 w-full break-words" href="#references">References</a>
      </li></ul>

  
  
    
    
  



    












  </div>
  </nav>


  <article class="w-full break-words flex min-h-[calc(100vh-var(--navbar-height))] min-w-0 justify-center pb-8 pr-[calc(env(safe-area-inset-right)-1.5rem)]">
    <main class="w-full min-w-0 max-w-6xl px-6 pt-4 md:px-12">

      

      <h1 class="mt-2 text-4xl font-bold tracking-tight text-slate-900 dark:text-slate-100">Doing Linear Algebra using Tensorflow 2</h1>

      <div class="mt-4 mb-16">
      <div class="text-gray-500 dark:text-gray-300 text-sm flex items-center flex-wrap gap-y-2"><span class="mr-1">May 14, 2020</span>
        

        
        <span class="mx-1">·</span>
        <span class="mx-1">
          54 min read
        </span>
        
        </div>

        <div class="mt-3">
          





        </div>
      </div>



      
      
      

      
      

      <div class="prose prose-slate lg:prose-xl dark:prose-invert">
        <table class="tfo-notebook-buttons" align="left">
  <td>
    <a href="https://colab.research.google.com/github/biswajitsahoo1111/blog_notebooks/blob/master/Doing_Linear_Algebra_using_Tensorflow_2.ipynb">
    <img src="https://www.tensorflow.org/images/colab_logo_32px.png" />
    Run in Google Colab</a>
  </td>
  <td>
    <a href="https://github.com/biswajitsahoo1111/blog_notebooks/blob/master/Doing_Linear_Algebra_using_Tensorflow_2.ipynb">
    <img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />
    View source on GitHub</a>
  </td>
  <td>
    <a href="https://www.dropbox.com/s/vtp81fo71uo9ctn/Doing_Linear_Algebra_using_Tensorflow_2.ipynb?dl=1"><img src="https://www.tensorflow.org/images/download_logo_32px.png" />Download notebook</a>
  </td>
</table>
<p>In this post, we will explore ways of doing linear algebra <strong>only</strong> using <code>tensorflow</code>. We will only import <code>tensorflow</code> and nothing else. As we will see, we can do all the common linear algebra operations without using any other library. This post is very long as it covers almost all the functions that are there in the linear algebra library <code>tf.linalg</code>. But this is not a copy of <code>tensorflow</code> documentation. Rather, the <code>tensorflow</code> documentation is a super set of what has been discussed here. This post also assumes that readers have a working knowledge of linear algebra. Most of the times, we will give examples to illustrate a function without going into the underlying theory. Interested readers should use the contents to browse relevant sections of their interest.</p>
<!-- * [Basics](#basics)
  * [Creating tensors](#creating_tensors)
  * [Creating a sequence of numbers](#creating_a_sequence_of_numbers)
  * [Slicing](#slicing)
  * [Modifying elements of a matrix](#modifying_elements_of_a_matrix)
  * [Creating a complex matrix](#creating_a_complex_matrix)
  * [Transpose of a matrix](#transpose_of_a_matrix)
    * [Transpose of a real matrix](#transpose_of_a_real_matrix)
    * [Transpose of a complex matrix](#transpose_of_a_complex_matrix)
  * [Some common matrices](#some_common_matrices)
    * [Identity matrix](#identity_matrix)
    * [Diagonal matrix](#diagonal_matrix)
    * [Tri-diagonal matrix](#tri-diagonal_matrix)
    * [Matrix of all zeros and ones](#matrix_of_all_zeros_and_ones)
    * [Random matrices](#random_matrices)
      * [Random uniform matrix](#random_uniform_matrix)
      * [Random normal matrix](#random_normal_matrix)
      * [Truncated random normal matrix](#truncated_random_normal_matrix)
      * [Random Poisson matrix](#random_poisson_matrix)
      * [Random gamma matrix](#random_gamma_matrix)
    * [Some special matrices](#some_special_matrices)
  * [Sparse matrices](#sparse_matrices)
  * [Matrix multiplication](#matrix_multiplication)
    * [Multiplying two column vectors](#multiplying_two_column_vectors)
      * [Inner product](#inner_product)
      * [Outer product](#outer_product)
    * [Multiplying a matrix with a vector](#multiplying_a_matrix_with_a_vector)
    * [Multiplying two matrices](#multiplying_two_matrices)
    * [Multiplying two tri-diagonal matrices](#multiplying_two_tri-diagonal_matrices)
  * [Some common operations on matrices](#some_common_operations_on_matrices)
    * [Trace](#trace)
    * [Determinant](#determinant)
    * [Rank](#rank)
    * [Matrix inverse](#matrix_inverse)
    * [Extract diagonals of a matrix](#extract_diagonals_of_a_matrix)
    * [Extract band part of a matrix](#extract_band_part_of_a_matrix)
* [Matrix factorizations](#matrix_factorizations)
  * [LU](#lu)
  * [Cholesky](#cholesky)
  * [QR](#qr)
  * [SVD](#svd)
* [Eigenvalues and eigenvectors](#eigenvalues_and_eigenvectors)
  * [Eigen-analysis of Hermitian matrices](#eigen-analysis_of_hermitian_matrices)
  * [Eigen-analysis of non-Hermitian matrices](#eigen-analysis_of_non-Hermitian_matrices)
* [Solving dense linear systems](#solving_dense_linear_systems)
  * [Using LU decomposition](#using_lu_decomposition)
  * [Using Cholesky decomposition](#using_cholesky_decomposition)
* [Solving structured linear systems](#solving_structured_linear_systems)
  * [Solving triangular systems](#solving_triangular_systems)
  * [Solving tri-diagonal systems](#solving_tri-diagonal_systems)
  * [Solving banded triangular systems](#solving_banded_triangular_systems)
* [Solving least squares problems](#solving_least_squares_problems)
  * [Ordinary least squares](#ordinary_least_squares)
  * [Regularized least squares](#regularized_least_squares)
* [Some specialized operations](#some_specialized_operations)
  * [Norm](#norm)
  * [Normalizing a tensor](#normalizing_a_tensor)
  * [Global norm](#global_norm)
  * [Cross product of vectors](#cross_product_of_vectors)
  * [Matrix square root](#matrix_square_root)
  * [Matrix exponential](#matrix_exponential)
  * [Matrix logarithm](#matrix_logarithm)
  * [Log-determinant of a matrix](#log-determinant_of_a_matrix)
  * [Pseudo inverse of a matrix](#pseudo_inverse_of_a_matrix)
* [Linear operators](#linear_operators)
  * [Common methods on linear operators](#common_methods_on_linear_operators)
  * [Special matrices using operators](#special_matrices_using_operators)
    * [Toeplitz matrix](#toeplitz_matrix)
    * [Circulant matrix](#circulant_matrix)
    * [Block diagonal matrix](#block_diagonal_matrix)
    * [Block lower triangular matrix](#block_lower_triangular_matrix)
    * [Householder matrix](#householder_matrix)
    * [Kronecker matrix](#kronecker_matrix)
    * [Permutation matrix](#permutation_matrix)
  * [Common matrices using operators](#common_matrices_using_operators)
    * [Identity matrix](#identity_matrix)
    * [Scaled identity matrix](#scaled_identity_matrix)
    * [Diagonal matrix](#diagonal_matrix)
    * [Tri-diagonal matrix](#tri-diagonal_matrix)
    * [Lower triangular matrix](#lower_triangular_matrix)
    * [Matrix of zeros](#matrix_of_zeros)
  * [Matrix operations using operators](#matrix_operations_using_operators)
    * [Low-rank update](#low-rank_update)
    * [Operator inversion](#operator_inversion)
    * [Operator composition](#operator_composition)
* [Conclusion](#conclusion) -->
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>2.3.0
</code></pre>
<p>One thing we have to keep in mind is that while accessing a function, we have to always append the function by <code>tf.linalg</code>. It is possible to remove the <code>tf</code> part by importing the <code>linalg</code> library from <code>tensorflow</code>. But even then we have to append every function by <code>linalg</code>. In this post, we will always use <code>tf.linalg</code> followed by function name. This amounts to little more typing. But we will do this to remind ourselves that we are using <code>linalg</code> library of <code>tensorflow</code>. This might seem little awkward to seasoned users of <code>MATLAB</code> or <code>Julia</code> where you just need to type the function name to use it without having to write the library name all the time. Except that, linear algebra in <code>tensorflow</code> seems quite natural.</p>
<p><strong>Note</strong>: In this post, we will show some of the ways in which we can handle matrix operations in <code>Tensorflow</code>. We will mainly use 1D or 2D arrays in our examples. But matrix operations in Tensorflow are not limited to 2D arrays. In fact, the operations can be done on multidimensional arrays. If an array has more than 2 dimensions, the matrix operation is done on the <strong>last two</strong> dimensions and the same operation is carried across other dimensions. For example, if our array has a shape of (3,5,5), it can be thought of as 3 matrices each of shape (5,5). When we call a matrix function on this array, the matrix function is applied to all 3 matrices of shape (5,5). This is also true for higher dimensional arrays.</p>
<p><a id="basics"></a></p>
<h2 id="basics">Basics</h2>
<p>Tensorflow operates on <code>Tensors</code>. <code>Tensors</code> are characterized by their rank. Following table shows different types of tensors and their corresponding rank.</p>
<table>
  <thead>
      <tr>
          <th style="text-align: center">Tensors</th>
          <th style="text-align: center">Rank</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center">Scalars</td>
          <td style="text-align: center">Rank 0 Tensor</td>
      </tr>
      <tr>
          <td style="text-align: center">Vectors (1D array)</td>
          <td style="text-align: center">Rank 1 Tensor</td>
      </tr>
      <tr>
          <td style="text-align: center">Matrices (2D array)</td>
          <td style="text-align: center">Rank 2 Tensor</td>
      </tr>
      <tr>
          <td style="text-align: center">3D array</td>
          <td style="text-align: center">Rank 3 Tensor</td>
      </tr>
  </tbody>
</table>
<p><a id = "creating_tensors"></a></p>
<h3 id="creating-tensors">Creating tensors</h3>
<p>In this section, we will create <code>tensors</code> of different rank, starting from scalars to multi-dimensional arrays. Though tensors can be both real or complex, we will mainly focus on real tensors.</p>
<p>A scalar contains a single (real or complex) value.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">5.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">a</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(), dtype=float32, numpy=5.0&gt;
</code></pre>
<p>The output shows that the result is a <code>tf.Tensor</code>. As scalars are rank 0 tensors, its shape is empty. Data type of the tensor is <code>float32</code>. And corresponding numpy array is 5. We can get only the value of the tensor by calling <code>numpy</code> method.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">a</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>5.0
</code></pre>
<p>Similarly, we can define 1D and 2D <code>tensors</code>. While 1D <code>tensors</code> are called vectors, 2D <code>tensors</code> are called matrices.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">9</span><span class="p">])</span>    <span class="c1"># Note the shape in result. Only one shape parameter is used for vectors.</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4,), dtype=int32, numpy=array([1, 3, 7, 9], dtype=int32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">            <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">]])</span>     <span class="c1"># Note the shape in result. There are two shape parameters (rows, columns).</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 4), dtype=int32, numpy=
array([[1, 2, 3, 4],
       [5, 6, 7, 8]], dtype=int32)&gt;
</code></pre>
<p>Another way to define a 2D array is given below.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mf">8.0</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 4), dtype=float32, numpy=
array([[1., 2., 3., 4.],
       [5., 6., 7., 8.]], dtype=float32)&gt;
</code></pre>
<p><a id = "creating_a_sequence_of_numbers"></a></p>
<h3 id="creating-a-sequence-of-numbers">Creating a sequence of numbers</h3>
<p>There are two ways to generate sequence of numbers in <code>Tensorflow</code>. Functions <code>tf.range</code> and <code>tf.linspace</code> can be used for that purpose. Sequences generated by these functions are equally spaced.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sequence</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="n">limit</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sequence</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)
</code></pre>
<p>Note that the last element (limit) is not included in the array. This is consistent with <code>Python</code> behavior but in departure with <code>MATLAB</code> and <code>Julia</code> convention. It is also possible to set <code>delta</code> to a fraction.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">delta</span> <span class="o">=</span> <span class="mf">1.5</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([1. , 2.5, 4. , 5.5, 7. , 8.5], dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num</span> <span class="o">=</span> <span class="mi">25</span><span class="p">)</span>  <span class="c1"># Start must be a `float`. See documentation for more details.</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(25,), dtype=float32, numpy=
array([ 1.   ,  1.375,  1.75 ,  2.125,  2.5  ,  2.875,  3.25 ,  3.625,
        4.   ,  4.375,  4.75 ,  5.125,  5.5  ,  5.875,  6.25 ,  6.625,
        7.   ,  7.375,  7.75 ,  8.125,  8.5  ,  8.875,  9.25 ,  9.625,
       10.   ], dtype=float32)&gt;
</code></pre>
<p>Though in this post we will mainly focus on matrices, it is easy to create higher dimensional arrays in <code>Tensorflow</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=
array([[[ 1,  2],
        [ 3,  4],
        [ 5,  6]],

       [[ 7,  8],
        [ 9, 10],
        [11, 12]]], dtype=int32)&gt;
</code></pre>
<p><a id = "slicing"></a></p>
<h3 id="slicing">Slicing</h3>
<p>Slicing is similar to that of <code>numpy</code> slicing. For vectors (rank 1 tensor with only one shape parameter), only one argument is passed that corresponds to the location of starting index and end index of sliced array. For matrices (rank 2 tensor with two shape parameters), two input arguments need to be passed. First one for rows and second one for columns.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">vector</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">start</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">limit</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vector</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">vector</span><span class="p">[</span><span class="mi">3</span><span class="p">:</span><span class="mi">7</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> 
</span></span></code></pre></div><pre><code>array([4, 5, 6, 7], dtype=int32)
</code></pre>
<p>Indexing in <code>tensorflow</code> starts from zero. In the above example, start index is 3. So that corresponds to 4th element of the vector. And end index is not included. This is similar to <code>Python</code> convention.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">matrix</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">matrix</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.,  4.],
       [ 5.,  6.,  7.,  8.,  9.],
       [10., 11., 12., 13., 14.],
       [15., 16., 17., 18., 19.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">matrix</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=
array([[ 7.,  8.],
       [12., 13.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">matrix</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">:]</span>      <span class="c1"># Same behavior as numpy</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[ 2.,  3.,  4.],
       [ 7.,  8.,  9.],
       [12., 13., 14.]], dtype=float32)&gt;
</code></pre>
<p><a id = "modifying_elements_of_a_matrix"></a></p>
<h3 id="modifying-elements-of-a-matrix">Modifying elements of a matrix</h3>
<p><code>Tensors</code> in <code>tensorflow</code>, once created, can&rsquo;t be modified. So the following code segment will result in an error.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-gdscript3" data-lang="gdscript3"><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="o">&gt;&gt;&gt;</span> <span class="n">a</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># Error</span>
</span></span></code></pre></div><p>But there is a way to modify values of a matrix. Instead of creating a <code>tensor</code>, we create a <code>Variable</code>. <code>Variables</code> work just like <code>tensors</code> with the added advantage that their values can be modified. So if we want to modify entries of our matrix at a later stage, we have to first create our matrix as a variable. Then we can do assignment using <code>assign</code> command.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">variable_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="n">variable_mat</span>
</span></span></code></pre></div><pre><code>&lt;tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.],
       [ 4.,  5.,  6.,  7.],
       [ 8.,  9., 10., 11.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">variable_mat</span><span class="p">[:</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="n">variable_mat</span>
</span></span></code></pre></div><pre><code>&lt;tf.Variable 'Variable:0' shape=(3, 4) dtype=float32, numpy=
array([[ 0.,  1., -1., -1.],
       [ 4.,  5., -1., -1.],
       [ 8.,  9., 10., 11.]], dtype=float32)&gt;
</code></pre>
<p><a id = "creating_a_complex_matrix"></a></p>
<h3 id="creating-a-complex-matrix">Creating a complex matrix</h3>
<p>To create a complex matrix, we have to first create the real part and imaginary part separately. Then both real and imaginary parts can be combined element wise to create a complex matrix. Elements of both real and imaginary part should be floats. This is the hard way of creating complex a complex matrix. We will discuss the simpler way next.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">real_part</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">minval</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">maxval</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">imag_part</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> <span class="n">minval</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">maxval</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Real part:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">real_part</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Imaginary part:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">imag_part</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Real part:
tf.Tensor(
[[3.8433075 4.279177 ]
 [2.409762  1.238677 ]
 [2.4724636 1.6782365]], shape=(3, 2), dtype=float32)

Imaginary part:
tf.Tensor(
[[2.90653   4.282353 ]
 [1.0855489 1.4715123]
 [1.3954673 4.987824 ]], shape=(3, 2), dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">complex_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">complex</span><span class="p">(</span><span class="n">real</span> <span class="o">=</span> <span class="n">real_part</span><span class="p">,</span> <span class="n">imag</span> <span class="o">=</span> <span class="n">imag_part</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">complex_mat</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>tf.Tensor(
[[3.8433075+2.90653j   4.279177 +4.282353j ]
 [2.409762 +1.0855489j 1.238677 +1.4715123j]
 [2.4724636+1.3954673j 1.6782365+4.987824j ]], shape=(3, 2), dtype=complex64)
</code></pre>
<p>There is a simpler way to create a complex matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">complex_mat_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="o">+</span><span class="mi">2</span><span class="n">j</span><span class="p">,</span> <span class="mi">2</span><span class="o">+</span><span class="mi">3</span><span class="n">j</span> <span class="p">,</span> <span class="mi">3</span><span class="o">+</span><span class="mi">4</span><span class="n">j</span><span class="p">,</span> <span class="mi">4</span><span class="o">+</span><span class="mi">5</span><span class="n">j</span><span class="p">,</span> <span class="mi">5</span><span class="o">+</span><span class="mi">6</span><span class="n">j</span><span class="p">,</span> <span class="mi">6</span><span class="o">+</span><span class="mi">7</span><span class="n">j</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">complex_mat_2</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 3), dtype=complex128, numpy=
array([[1.+2.j, 2.+3.j, 3.+4.j],
       [4.+5.j, 5.+6.j, 6.+7.j]])&gt;
</code></pre>
<p><a id = "transpose_of_a_matrix"></a></p>
<h3 id="transpose-of-a-matrix">Transpose of a matrix</h3>
<p><a id = "transpose_of_a_real_matrix"></a></p>
<h4 id="transpose-of-a-real-matrix">Transpose of a real matrix</h4>
<p>For real matrices <code>transpose</code> just means changing the rows into columns and vice versa. There are three functions that achieve this.</p>
<ul>
<li><code>tf.transpose</code></li>
<li><code>tf.adjoint</code></li>
<li><code>tf.matrix_transpose</code></li>
</ul>
<p>For real matrices, all three functions give identical results.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">matrix</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.,  4.],
       [ 5.,  6.,  7.,  8.,  9.],
       [10., 11., 12., 13., 14.],
       [15., 16., 17., 18., 19.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  5., 10., 15.],
       [ 1.,  6., 11., 16.],
       [ 2.,  7., 12., 17.],
       [ 3.,  8., 13., 18.],
       [ 4.,  9., 14., 19.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">adjoint</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  5., 10., 15.],
       [ 1.,  6., 11., 16.],
       [ 2.,  7., 12., 17.],
       [ 3.,  8., 13., 18.],
       [ 4.,  9., 14., 19.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_transpose</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 4), dtype=float32, numpy=
array([[ 0.,  5., 10., 15.],
       [ 1.,  6., 11., 16.],
       [ 2.,  7., 12., 17.],
       [ 3.,  8., 13., 18.],
       [ 4.,  9., 14., 19.]], dtype=float32)&gt;
</code></pre>
<p><a id = "transpose_of_a_complex_matrix"></a></p>
<h4 id="transpose-of-a-complex-matrix">Transpose of a complex matrix</h4>
<p>Things are little different when we have a complex matrix. For complex matrices, we can take regular transpose or conjugate transpose if we want. Default is regular transpose. To take conjugate transpose, we have to set <code>conjugate = False</code> in <code>tf.transpose</code> and <code>tf.linalg.matrix_transpose</code> or use <code>tf.linalg.adjoint</code> function.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">complex_mat_2</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[1.+2.j, 2.+3.j, 3.+4.j],
       [4.+5.j, 5.+6.j, 6.+7.j]])
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">transpose_of_complex_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">complex_mat_2</span><span class="p">,</span> <span class="n">conjugate</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="c1"># Regular transpose</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">transpose_of_complex_mat</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>tf.Tensor(
[[1.+2.j 4.+5.j]
 [2.+3.j 5.+6.j]
 [3.+4.j 6.+7.j]], shape=(3, 2), dtype=complex128)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">conjugate_transpose_of_complex_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">complex_mat_2</span><span class="p">,</span> <span class="n">conjugate</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="c1"># Conjugate transpose</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">conjugate_transpose_of_complex_mat</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>tf.Tensor(
[[1.-2.j 4.-5.j]
 [2.-3.j 5.-6.j]
 [3.-4.j 6.-7.j]], shape=(3, 2), dtype=complex128)
</code></pre>
<p>We can also do conjugate transpose by using function <code>linalg.adjoint</code> function.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">adjoint</span><span class="p">(</span><span class="n">complex_mat_2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[1.-2.j, 4.-5.j],
       [2.-3.j, 5.-6.j],
       [3.-4.j, 6.-7.j]])
</code></pre>
<p>Another way to take transpose of a matrix is to use the function <code>linalg.matrix_transpose</code>. In this function, we can set argument <code>conjugate</code> to <code>True</code> or <code>False</code> depending on whether we want regular transpose or conjugate transpose. Default is <code>conjugate = False</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_transpose</span><span class="p">(</span><span class="n">complex_mat_2</span><span class="p">)</span>   <span class="c1"># Conjugate = False is the default</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 2), dtype=complex128, numpy=
array([[1.+2.j, 4.+5.j],
       [2.+3.j, 5.+6.j],
       [3.+4.j, 6.+7.j]])&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_transpose</span><span class="p">(</span><span class="n">complex_mat_2</span><span class="p">,</span> <span class="n">conjugate</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 2), dtype=complex128, numpy=
array([[1.-2.j, 4.-5.j],
       [2.-3.j, 5.-6.j],
       [3.-4.j, 6.-7.j]])&gt;
</code></pre>
<p><a id = "some_common_matrices"></a></p>
<h3 id="some-common-matrices">Some common matrices</h3>
<p><a id = "identity_matrix"></a></p>
<h4 id="identity-matrix">Identity matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 1.]], dtype=float32)&gt;
</code></pre>
<p><a id = "diagonal_matrix"></a></p>
<h4 id="diagonal-matrix">Diagonal matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=int32, numpy=
array([[1, 0, 0, 0, 0],
       [0, 2, 0, 0, 0],
       [0, 0, 3, 0, 0],
       [0, 0, 0, 4, 0],
       [0, 0, 0, 0, 5]], dtype=int32)&gt;
</code></pre>
<p>To create diagonal matrix, we can also use <code>tf.linalg.tensor_diag</code> with main diagonal as input.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tensor_diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mf">5.</span><span class="p">]))</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 0., 0., 0., 0.],
       [0., 2., 0., 0., 0.],
       [0., 0., 3., 0., 0.],
       [0., 0., 0., 4., 0.],
       [0., 0., 0., 0., 5.]], dtype=float32)&gt;
</code></pre>
<p>We can also create a matrix whose only nonzero entries are on its super-diagonals or sub-diagonals.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>   <span class="c1"># Values in super-diagonal</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=int32, numpy=
array([[0, 1, 0, 0, 0],
       [0, 0, 2, 0, 0],
       [0, 0, 0, 3, 0],
       [0, 0, 0, 0, 4],
       [0, 0, 0, 0, 0]], dtype=int32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="n">k</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Values in sub-diagonal</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=int32, numpy=
array([[0, 0, 0, 0, 0],
       [1, 0, 0, 0, 0],
       [0, 2, 0, 0, 0],
       [0, 0, 3, 0, 0],
       [0, 0, 0, 4, 0]], dtype=int32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">padding_value</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=int32, numpy=
array([[ 1, -1, -1, -1, -1],
       [-1,  2, -1, -1, -1],
       [-1, -1,  3, -1, -1],
       [-1, -1, -1,  4, -1],
       [-1, -1, -1, -1,  5]], dtype=int32)&gt;
</code></pre>
<p>Another way to create a diagonal matrix is by using <code>tf.linalg.set_diag</code> function.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">diag</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mf">5.</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">set_diag</span><span class="p">(</span><span class="nb">input</span> <span class="o">=</span> <span class="n">mat</span><span class="p">,</span> <span class="n">diagonal</span> <span class="o">=</span> <span class="n">diag</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 0., 0., 0., 0.],
       [0., 2., 0., 0., 0.],
       [0., 0., 3., 0., 0.],
       [0., 0., 0., 4., 0.],
       [0., 0., 0., 0., 5.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">set_diag</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mf">4.</span><span class="p">]),</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>  <span class="c1"># Set super-diagonal</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[0., 1., 0., 0., 0.],
       [0., 0., 2., 0., 0.],
       [0., 0., 0., 3., 0.],
       [0., 0., 0., 0., 4.],
       [0., 0., 0., 0., 0.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">diags</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mf">0.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">set_diag</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">diags</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 0., 0., 0., 0.],
       [6., 2., 0., 0., 0.],
       [0., 7., 3., 0., 0.],
       [0., 0., 8., 4., 0.],
       [0., 0., 0., 9., 5.]], dtype=float32)&gt;
</code></pre>
<h4 id="note-on-alignment-strategy">Note on alignment strategy</h4>
<p>Functions like <code>tf.linalg.diag</code> and <code>tf.linalg.set_diag</code> and several others to be seen later, take an argument called <code>align</code> among other things. Though up to this point we have used default parameters of <code>align</code>, we believe, a note is warranted at this point. There are four different alignment strategies in tensorflow. Those are:</p>
<ul>
<li><code>LEFT_LEFT</code>: Superdiagonals are <code>appended at right</code> and subdiagonals are <code>appended at right</code>.</li>
<li><code>LEFT_RIGHT</code>: Superdiagonals are <code>appended at right</code> and subdiagonals are <code>appended at left</code>.</li>
<li><code>RIGHT_LEFT</code>: Superdiagonals are <code>appended at left</code> and subdiagonals are <code>appended at right</code>.</li>
<li><code>RIGHT_RIGHT</code>: Superdiagonals are <code>appended at left</code> and subdiagonals are <code>appended at left</code>.</li>
</ul>
<p>One way to remember the above rules is that if something is aligned to left, it is appended at right. And in <code>LEFT_RIGHT</code>, first word corresponds to superdiagonals and second word corresponds to subdiagonals.</p>
<h4 id="why-do-we-need-an-alignment-strategy">Why do we need an alignment strategy?</h4>
<p>Both superdiagonals and subdiagonals have less number of entries than the main diagonal. If we extract (for some reason) the subdiagonals (or superdiagonals) of a matrix along with the main diagonal, the resulting array will have different lengths. These type of arrays are called <code>ragged array</code>s. Though <code>tensorflow</code> can handle <code>ragged array</code>s, the results of linear algebra library are always uniform arrays (i.e., all the arrays have same number of entries). So while extracting subdiagonals (or superdiagonals), we have to append it either at the left or at right to make it of the same length as the main diagonal. This leads to the question of where the arrays should be appended. <code>Tensorflow</code> leaves that option to the readers. Depending on where we append the subdiagonals and superdiagonals, there are four alignment strategies as mentioned below.</p>
<p>In the next section, we will see a way to create tri-diagonal matrix using <code>tf.linalg.set_diag</code>.</p>
<p><a id = "tri-diagonal_matrix"></a></p>
<h4 id="tri-diagonal-matrix">Tri-diagonal matrix</h4>
<p>Let&rsquo;s create <a href="http://www-math.mit.edu/~gs/" target="_blank" rel="noopener">Gilbert Strang&rsquo;s</a> favorite matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="n">repeats</span> <span class="o">=</span> <span class="mi">5</span><span class="p">))</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="mi">4</span><span class="p">),</span> <span class="n">k</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">repeats</span> <span class="o">=</span> <span class="mi">4</span><span class="p">),</span> <span class="n">k</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=int32, numpy=
array([[ 2, -1,  0,  0,  0],
       [-1,  2, -1,  0,  0],
       [ 0, -1,  2, -1,  0],
       [ 0,  0, -1,  2, -1],
       [ 0,  0,  0, -1,  2]], dtype=int32)&gt;
</code></pre>
<h4 id="tri-digonal-matrix-using-tflinalgset_diag">Tri-digonal matrix using <code>tf.linalg.set_diag</code></h4>
<p>While setting more that one diagonals using <code>set_diag</code>, say <code>k = (-2,3)</code>, we have to have 6 diagonals (2 sub-diagonals, 1 main diagonal, and 3 super-diagonals). First three rows of the input diagonals will correspond to super-diagonals and have to be appended at the right by zeros (according to alignment strategy of <code>&quot;LEFT_RIGHT&quot;</code>). Fourth row corresponds to main diagonal. Last two rows correspond to sub-diagonals and have to be appended at the left by zeros (according to alignment strategy of <code>&quot;LEFT_RIGHT&quot;</code>). We could have chosen any other alignment strategy and modified our input accordingly. Using this rule, now we will create a tri-diagonal matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">diags</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span> <span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">set_diag</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span><span class="n">diags</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">align</span> <span class="o">=</span> <span class="s2">&#34;LEFT_RIGHT&#34;</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 2., -1.,  0.,  0.,  0.],
       [-1.,  2., -1.,  0.,  0.],
       [ 0., -1.,  2., -1.,  0.],
       [ 0.,  0., -1.,  2., -1.],
       [ 0.,  0.,  0., -1.,  2.]], dtype=float32)&gt;
</code></pre>
<p>There is yet another simpler way to create a tri-diagonal matrix using a linear operator. We will see that technique in a later section.</p>
<p><a id = "matrix_of_all_zeros_and_ones"></a></p>
<h4 id="matrix-of-all-zeros-and-ones">Matrix of all zeros and ones</h4>
<p>Matrices of all 1s or all 0s are not in <code>linalg</code> library. But those are available in core <code>Tensorflow</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 5), dtype=float32, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 4), dtype=int32, numpy=
array([[1, 1, 1, 1],
       [1, 1, 1, 1],
       [1, 1, 1, 1],
       [1, 1, 1, 1],
       [1, 1, 1, 1]], dtype=int32)&gt;
</code></pre>
<p><a id = "random_matrices"></a></p>
<h4 id="random-matrices">Random matrices</h4>
<p>Random matrices are also not part of <code>linalg</code> library. Rather, they are part of <code>tf.random</code> library. Using <code>Tensorflow</code> we can create matrices whose entries come from normal, uniform, poisson, and gamma distributions.</p>
<p><a id = "random_uniform_matrix"></a></p>
<h5 id="random-uniform-matrix">Random uniform matrix</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">minval</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">maxval</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span> <span class="mi">32</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[4.8578553 , 0.26324332, 1.7549878 , 4.434555  , 2.3975224 ],
       [3.219039  , 0.4039365 , 0.92039883, 2.9136662 , 4.9377174 ],
       [4.617196  , 3.6782126 , 4.0351195 , 4.8321657 , 4.206293  ],
       [2.3059547 , 4.922245  , 4.186061  , 2.1761923 , 0.88124394],
       [2.7422066 , 1.5948689 , 2.6099925 , 4.4901986 , 2.4033623 ]],
      dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Random matrix of integers</span>
</span></span><span class="line"><span class="cl"><span class="n">uniform_int</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">minval</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">maxval</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">1234</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">uniform_int</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=int32, numpy=
array([[19, 15, 13, 14, 10],
       [16, 18, 10, 15, 10],
       [12, 13, 19, 12, 16],
       [18, 11, 10, 18, 12],
       [17, 18, 14, 19, 10]], dtype=int32)&gt;
</code></pre>
<p>For further processing we usually require matrix entries to  be floating point numbers. This can be achieved by using <code>tf.cast</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">dtypes</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">uniform_int</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[19., 15., 13., 14., 10.],
       [16., 18., 10., 15., 10.],
       [12., 13., 19., 12., 16.],
       [18., 11., 10., 18., 12.],
       [17., 18., 14., 19., 10.]], dtype=float32)&gt;
</code></pre>
<p><a id = "random_normal_matrix"></a></p>
<h5 id="random-normal-matrix">Random normal matrix</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">mean</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">253</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 1.5266892 , -5.114835  ,  4.4653835 , -1.013567  , -1.1874261 ],
       [ 5.503375  , -1.4568713 , -1.3270268 ,  0.2747649 ,  3.1374507 ],
       [ 4.211556  ,  4.618066  ,  1.2217634 ,  0.04707384,  1.4131291 ],
       [-2.7024255 ,  0.81293994, -3.11763   , -3.043394  ,  5.5663233 ],
       [ 1.4549919 ,  3.7368293 ,  1.2184538 ,  2.0713992 ,  0.19450545]],
      dtype=float32)&gt;
</code></pre>
<p><a id = "truncated_random_normal_matrix"></a></p>
<h5 id="truncated-random-normal-matrix">Truncated random normal matrix</h5>
<p><code>truncated_normal</code> function gives values within two standard deviations of mean on both sides of normal curve.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">truncated_normal</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">mean</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">82</span><span class="p">)</span> 
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 2.3130474 ,  1.917585  ,  1.1134342 , -3.6221776 , -2.242488  ],
       [ 2.8108876 , -1.8440692 ,  1.7630143 , -0.4591654 , -0.20763761],
       [-0.4769438 ,  2.3582413 , -0.45690525, -0.4208855 , -1.8990422 ],
       [-2.2638845 ,  2.9536312 ,  0.9591611 ,  2.670887  ,  1.4793464 ],
       [-0.60492915,  3.6320126 ,  3.9752324 , -0.4684417 , -3.2791114 ]],
      dtype=float32)&gt;
</code></pre>
<p>There are ways to create deterministic random numbers using <code>stateless_normal</code>, <code>stateless_uniform</code>, etc. To know more about random number generation in <code>Tensorflow</code>, go to <a href="https://www.tensorflow.org/guide/random_numbers" target="_blank" rel="noopener">this link</a></p>
<p><a id = "random_poisson_matrix"></a></p>
<h5 id="random-poisson-matrix">Random Poisson matrix</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">lam</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 0., 1., 2., 3.],
       [0., 1., 2., 3., 4.],
       [2., 0., 2., 2., 2.],
       [2., 0., 2., 2., 3.],
       [1., 4., 2., 5., 4.]], dtype=float32)&gt;
</code></pre>
<p><a id = "random_gamma_matrix"></a></p>
<h5 id="random-gamma-matrix">Random gamma matrix</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">gamma</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">232</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[0.78733766, 2.5200539 , 0.9812998 , 5.141082  , 1.9184761 ],
       [1.1069427 , 0.32923967, 0.13172682, 5.066955  , 2.8487072 ],
       [0.39204285, 0.53647757, 5.3083944 , 1.618826  , 0.41352856],
       [1.0327125 , 0.27330002, 0.34577194, 0.22123706, 0.77021873],
       [0.38616025, 9.153643  , 1.4737413 , 6.029133  , 0.05517024]],
      dtype=float32)&gt;
</code></pre>
<p><a id = "some_special_matrices"></a></p>
<h4 id="some-special-matrices">Some special matrices</h4>
<p>Special matrices like <code>toeplitz</code>, <code>circulant</code>, <code>Kronecker</code>, etc can be created using linear operators. We will discuss this in the <a href="#special_matrices_using_operators">linear operator</a> section.</p>
<p><a id = "sparse_matrices"></a></p>
<h3 id="sparse-matrices">Sparse matrices</h3>
<p>Sparse matrices are within <code>tf.sparse</code> library. There are several functions specifically designed for sparse matrices. Full list of function in <code>tf.sparse</code> library can be found at <a href="https://www.tensorflow.org/api_docs/python/tf/sparse" target="_blank" rel="noopener">this link</a>. In this section, we will see how sparse matrices are created. The first argument is set of indices (rows and columns), second argument is the values at those indices. Third argument is the <code>dense_shape</code> of the sparse matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">sparse_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">SparseTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">]],</span> <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">dense_shape</span><span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">sparse_mat</span>
</span></span></code></pre></div><pre><code>&lt;tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f8f505203a0&gt;
</code></pre>
<p>To see the actual matrix, we have to convert the sparse matrix to a dense matrix. This is achieved using <code>to_dense</code> function.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">sparse</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(</span><span class="n">sparse_mat</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=int32, numpy=
array([[  0,  -5,   0,   0,   0],
       [  0,   0,   0, -10,   0],
       [  0,   0,   0,   0,   0],
       [  0,   0,   7,   0,   0],
       [  0,   0,   0,   0,   0]], dtype=int32)&gt;
</code></pre>
<p>It should be noted that special algorithms exist to deal with sparse matrices. Those algorithms don&rsquo;t require the sparse matrix to be converted into its dense equivalent. By converting a sparse matrix into a dense one, all its special properties are lost. Therefore, sparse matrices should not be converted into dense ones.</p>
<p><a id = "matrix_multiplication"></a></p>
<h3 id="matrix-multiplication">Matrix multiplication</h3>
<p>To multiply two vectors, or two matrices, or a matrix with a vector in a linear algebra sense, we have to use <code>linalg.matmul</code> function. Using <code>*</code> operator in python does element wise multiplication with broadcasting wherever possible. So to multiply two matrices, we have to call <code>linalg.matmul</code> function. Inputs to <code>linalg.matmul</code> function are matrices. Therefore, while multiplying two arrays, we have to first convert them into vectors and then multiply. Also note that <code>linalg.matmul</code> is same as <code>tf.matmul</code>. Both are aliases.</p>
<p><a id = "multiplying_two_column_vectors"></a></p>
<h4 id="multiplying-two-column-vectors">Multiplying two column vectors</h4>
<p>Vectors in <code>tensorflow</code> have only 1 shape parameter, where as a column vector (a matrix with one column) has two shape parameters. For example, a vector $[1,2,3]$ has shape $(3,)$, but the column vector $[1,2,3]^T$ has shape $(3,1)$.</p>
<p><a id = "inner_product"></a></p>
<h5 id="inner-product">Inner product</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">vector_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">vector_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mf">4.</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">vector_1</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">vector_2</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># Inner product</span>
</span></span><span class="line"><span class="cl"><span class="n">result</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[20.]], dtype=float32)
</code></pre>
<p><a id = "outer_product"></a></p>
<h5 id="outer-product">Outer product</h5>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">vector_1</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">vector_2</span><span class="p">,</span> <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="c1"># Outer product</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[ 2.,  3.,  4.],
       [ 4.,  6.,  8.],
       [ 6.,  9., 12.]], dtype=float32)&gt;
</code></pre>
<p><a id = "multiplying_a_matrix_with_a_vector"></a></p>
<h4 id="multiplying-a-matrix-with-a-vector">Multiplying a matrix with a vector</h4>
<p>There are two ways in which we can achieve this. We can convert the vector into a column vector (matrix with 1 column) and then apply <code>tf.matmul</code>, or we can use the inbuilt function <code>tf.linalg.matvec</code> to multiply a matrix with a vector.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mat_1</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[1., 2., 3.],
       [4., 5., 6.]], dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">mat_1</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">vector_1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[14.],
       [32.]], dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matvec</span><span class="p">(</span><span class="n">mat_1</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.</span><span class="p">]))</span>    <span class="c1"># Note the shape of input vector and result.</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2,), dtype=float32, numpy=array([14., 32.], dtype=float32)&gt;
</code></pre>
<p><a id = "multiplying_two_matrices"></a></p>
<h4 id="multiplying-two-matrices">Multiplying two matrices</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">mat</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">mat</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="c1"># Without `transpose_a` argument, result will be an error.</span>
</span></span></code></pre></div><pre><code>array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">a</span> <span class="o">=</span> <span class="n">mat</span><span class="p">,</span> <span class="n">b</span> <span class="o">=</span> <span class="n">mat</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float32)
</code></pre>
<p><a id = "multiplying_two_tri-diagonal_matrices"></a></p>
<h4 id="multiplying-two-tri-diagonal-matrices">Multiplying two tri-diagonal matrices</h4>
<p>If matrices have sparse structure, usual matrix multiplication is not an efficient method for those type of matrices. Special algorithms are there that exploit the sparsity of the matrices.</p>
<p>One such sparse matrix is tri-diagonal matrix. It has nonzero entries only on its super-diagonal, main diagonal, and sub-diagonal. To multiply a tri-diagonal matrix with another matrix, we can use <code>tf.linalg.tridiagonal_matmul</code> function. Its first argument is the diagonals of tri-diagonal matrix and second argument is the matrix with which the tri-diagonal matrix needs to be multiplied.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">diagonals</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span> <span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">rhs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">4.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tridiagonal_matmul</span><span class="p">(</span><span class="n">diagonals</span><span class="p">,</span> <span class="n">rhs</span><span class="p">)</span> 
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[ 0.,  3.,  3.],
       [-1., -5., -3.],
       [-1.,  1.,  0.],
       [ 8.,  6.,  8.],
       [-3.,  2., -1.]], dtype=float32)&gt;
</code></pre>
<p>We can verify the result by dense matrix multiplication. However, note that this is only for verification. For large matrix multiplications involving tri-diagonal matrix, dense multiplication will be considerably slower.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tridiag_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">set_diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)),</span> <span class="n">diagonals</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">align</span> <span class="o">=</span> <span class="s2">&#34;LEFT_RIGHT&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tridiag_mat</span><span class="p">,</span> <span class="n">rhs</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 3), dtype=float32, numpy=
array([[ 0.,  3.,  3.],
       [-1., -5., -3.],
       [-1.,  1.,  0.],
       [ 8.,  6.,  8.],
       [-3.,  2., -1.]], dtype=float32)&gt;
</code></pre>
<h4 id="how-to-multiply-two-tri-diagonal-matrices">How to multiply two tri-diagonal matrices?</h4>
<p>In this case, we have to convert the right tri-diagonal matrix into a full matrix and then multiply it with the left one using only the diagonals of left tri-diagonal matrix. For example, we will multiply the previous tri-diagonal matrix with itself.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tridiagonal_matmul</span><span class="p">(</span><span class="n">diagonals</span><span class="p">,</span> <span class="n">rhs</span> <span class="o">=</span> <span class="n">tridiag_mat</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 5., -4.,  1.,  0.,  0.],
       [-4.,  6., -4.,  1.,  0.],
       [ 1., -4.,  6., -4.,  1.],
       [ 0.,  1., -4.,  6., -4.],
       [ 0.,  0.,  1., -4.,  5.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tridiag_mat</span><span class="p">,</span> <span class="n">tridiag_mat</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 5., -4.,  1.,  0.,  0.],
       [-4.,  6., -4.,  1.,  0.],
       [ 1., -4.,  6., -4.,  1.],
       [ 0.,  1., -4.,  6., -4.],
       [ 0.,  0.,  1., -4.,  5.]], dtype=float32)&gt;
</code></pre>
<p><a id = "some_common_operations_on_matrices"></a></p>
<h3 id="some-common-operations-on-matrices">Some common operations on matrices</h3>
<p><a id = "trace"></a></p>
<h4 id="trace">Trace</h4>
<p>Computes the trace of a tensor. For non-square rank 2 tensors, trace of the main diagonal is computed.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">9.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">              
</span></span></code></pre></div><pre><code>3.0
</code></pre>
<p><a id = "determinant"></a></p>
<h4 id="determinant">Determinant</h4>
<p>Computes the determinant of the matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(), dtype=float32, numpy=-48.0&gt;
</code></pre>
<p><a id = "rank"></a></p>
<h4 id="rank">Rank</h4>
<p>Computes the rank of a matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">3.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">rank</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Rank of A = &#34;</span><span class="p">,</span> <span class="n">rank</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span></code></pre></div><pre><code>Rank of A =  2
</code></pre>
<p><a id = "matrix_inverse"></a></p>
<h4 id="matrix-inverse">Matrix inverse</h4>
<p>Computes the matrix inverse if it exists. It uses $LU$ decomposition to calculate inverse. What happens if inverse doesn&rsquo;t exist? Here is the answer taken directly from <code>tensorflow</code> documentation:</p>
<blockquote>
<p>[&hellip;] If a matrix is not invertible there is no guarantee what the op does. It may detect the condition and raise an exception or it may simply return a garbage result. [&hellip;]</p>
</blockquote>
<p>Having read the documentation, we will apply the function to an invertible matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">4.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">A_inv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">A_inv</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>tf.Tensor(
[[ 1.5999998e+00 -3.9999992e-01 -6.0000008e-01]
 [-1.9999999e+00  9.9999994e-01  7.9472862e-08]
 [ 5.9999996e-01 -3.9999998e-01  3.9999998e-01]], shape=(3, 3), dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">A_inv</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[ 9.9999970e-01,  1.1920929e-07, -1.1920929e-07],
       [-5.9604645e-07,  1.0000002e+00,  0.0000000e+00],
       [-2.3841858e-07,  0.0000000e+00,  1.0000000e+00]], dtype=float32)&gt;
</code></pre>
<h4 id="inverse-using-lu-factors">Inverse using $LU$ factors</h4>
<p>If $LU$ decomposition result is already available from some prior computation, it can be used to compute the inverse using command <code>tf.linalg.lu_matrix_inverse</code>. This command basically solves the following system:</p>
$$AX=I \Leftrightarrow LUX=I$$<p>As $L$ and $U$ are lower and upper triangular respectively, two triangular systems can be solved to obtain $X$ which is nothing but $A^{-1}$. The triangular systems are $LY = I$ (this gives $Y$ as result) and $UX=Y$ (this gives $X$, i.e., $A^{-1}$ as result). Here, the right hand side has more than one column in both the triangular systems. We will see how to solve those triangular systems at a <a href="#solving_triangular_systems">later section</a>. For the time being, we will just compute the inverse using the built-in command.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">lu</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">A_inv_by_lu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_matrix_inverse</span><span class="p">(</span><span class="n">lu</span><span class="p">,</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">A_inv_by_lu</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[ 1.5999998e+00, -3.9999992e-01, -6.0000008e-01],
       [-1.9999999e+00,  9.9999994e-01,  7.9472862e-08],
       [ 5.9999996e-01, -3.9999998e-01,  3.9999998e-01]], dtype=float32)&gt;
</code></pre>
<p><a id = "extract_diagonals_of_a_matrix"></a></p>
<h4 id="extract-diagonals-of-a-matrix">Extract diagonals of a matrix</h4>
<p>Diagonals of a matrix can be extracted using <code>tf.linalg.diag_part</code> function. Diagonal entries are obtained by setting <code>k=0</code> which is the default. By setting <code>k</code> to any other value, either sub-diagonal or super-diagonal can be obtained.If two values are given to <code>k</code>, the values correspond respectively to the lower limit and upper limit of the diagonal. And the result contains all diagonals within those limits. The result is not a  matrix. It is an array of diagonals, appended if required. Sub-diagonals are appended at the right and super diagonals are appended at the left.</p>
<p>Another function <code>tf.linalg.tensor_diag_part</code> can be used to extract the main diagonal of the matrix. But it can extract only the main diagonal.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">minval</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">maxval</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mat</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=int32, numpy=
array([[10, 11,  3, 18,  6],
       [18,  1, 16, 14, 12],
       [ 4, 18, 12, 17,  1],
       [12,  7,  5,  3,  7],
       [ 9, 16, 11, 14,  8]], dtype=int32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag_part</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([10,  1, 12,  3,  8], dtype=int32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tensor_diag_part</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([10,  1, 12,  3,  8], dtype=int32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag_part</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[10,  1, 12,  3,  8],
       [18, 18,  5, 14,  0]], dtype=int32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag_part</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>  <span class="c1"># 2 subdiagonals, main diagonal, and 1 super diagonal</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 5), dtype=int32, numpy=
array([[ 0, 11, 16, 17,  7],
       [10,  1, 12,  3,  8],
       [18, 18,  5, 14,  0],
       [ 4,  7, 11,  0,  0]], dtype=int32)&gt;
</code></pre>
<p><a id = "extract_band_part_of_a_matrix"></a></p>
<h4 id="extract-band-part-of-a-matrix">Extract band part of a matrix</h4>
<p>A band matrix is one that has nonzero values along its diagonal and a few sub-diagonals and super-diagonals. All other entries are zero. It is a sparse matrix. All of its nonzero entries are concentrated in a band along the diagonal. For example, tri-diagonal matrix is a banded matrix. It has lower bandwidth of 1 and upper bandwidth of 1. It is possible for a matrix to have different upper and lower bandwidths. It is still called a banded matrix.</p>
<p>Banded matrices are useful because computations are significantly faster using these matrices as compared to dense matrices of same shape. If for some application, we want the band part of a matrix, we can use <code>linalg.band_part</code> function to extract it. This function takes three arguments (<code>input</code>, <code>num_lower</code>, <code>num_upper</code>). First argument is the tensor whose band part we want to extract. Second argument is the number of sub-diagonals to keep. If set to 0, no sub-diagonal is kept. <code>num_lower = -1</code> keeps all the sub-diagonals. Similarly for <code>num_upper</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">matrix</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">matrix</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 0.,  1.,  2.,  3.,  4.],
       [ 5.,  6.,  7.,  8.,  9.],
       [10., 11., 12., 13., 14.],
       [15., 16., 17., 18., 19.],
       [20., 21., 22., 23., 24.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">num_lower</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">num_upper</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 0.,  1.,  0.,  0.,  0.],
       [ 5.,  6.,  7.,  0.,  0.],
       [10., 11., 12., 13.,  0.],
       [ 0., 16., 17., 18., 19.],
       [ 0.,  0., 22., 23., 24.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">num_lower</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_upper</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>  <span class="c1"># Lower triangular part</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 0.,  0.,  0.,  0.,  0.],
       [ 5.,  6.,  0.,  0.,  0.],
       [10., 11., 12.,  0.,  0.],
       [15., 16., 17., 18.,  0.],
       [20., 21., 22., 23., 24.]], dtype=float32)&gt;
</code></pre>
<p><a id = "matrix_factorizations"></a></p>
<h2 id="matrix-factorizations">Matrix factorizations</h2>
<p>Some of the most common and widely used matrix factorizations are available in <code>Tensorflow</code>.</p>
<p><a id = "lu"></a></p>
<h3 id="lu">LU</h3>
$$A=LU$$$$PA = LU$$<p>
Where, $P$ is called the permutation matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="mi">24</span><span class="p">,</span> <span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">13</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="mi">21</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">19</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">18</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">lu</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>  <span class="c1"># As per documentation</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;LU = &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">lu</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;P = &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>LU = 
tf.Tensor(
[[ 24.          -5.         -13.           9.        ]
 [ -0.29166666  19.541666     4.2083335   21.625     ]
 [  0.04166667   0.21535183   6.635394     2.9680166 ]
 [  0.           0.9211088    0.32005137 -16.868896  ]], shape=(4, 4), dtype=float32)

P = 
tf.Tensor([1 2 0 3], shape=(4,), dtype=int32)
</code></pre>
$$A = P^TLU$$<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">L</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">lu</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag_part</span><span class="p">(</span><span class="n">lu</span><span class="p">))</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">lu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
</span></span><span class="line"><span class="cl"><span class="n">U</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">lu</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">permu_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorPermutation</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">P</span> <span class="o">=</span> <span class="n">permu_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;L:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;U:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">U</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;P:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>L:
tf.Tensor(
[[ 1.          0.          0.          0.        ]
 [-0.29166666  1.          0.          0.        ]
 [ 0.04166667  0.21535183  1.          0.        ]
 [ 0.          0.9211088   0.32005137  1.        ]], shape=(4, 4), dtype=float32)

U:
tf.Tensor(
[[ 24.         -5.        -13.          9.       ]
 [  0.         19.541666    4.2083335  21.625    ]
 [  0.          0.          6.635394    2.9680166]
 [  0.          0.          0.        -16.868896 ]], shape=(4, 4), dtype=float32)

P:
tf.Tensor(
[[0. 1. 0. 0.]
 [0. 0. 1. 0.]
 [1. 0. 0. 0.]
 [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">U</span><span class="p">),</span> <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[  1.       ,   4.0000005,   7.       ,   8.       ],
       [ 24.       ,  -5.       , -13.       ,   9.       ],
       [ -7.       ,  21.       ,   8.       ,  19.       ],
       [  0.       ,  18.       ,   6.       ,   3.999998 ]],
      dtype=float32)&gt;
</code></pre>
<p>We can easily reconstruct our original matrix from $LU$ factors using the function <code>tf.linalg.lu_reconstruct</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_reconstruct</span><span class="p">(</span><span class="n">lu</span><span class="p">,</span><span class="n">p</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[  1.       ,   4.0000005,   7.       ,   8.       ],
       [ 24.       ,  -5.       , -13.       ,   9.       ],
       [ -7.       ,  21.       ,   8.       ,  19.       ],
       [  0.       ,  18.       ,   6.       ,   3.999998 ]],
      dtype=float32)&gt;
</code></pre>
<p><a id = "cholesky"></a></p>
<h3 id="cholesky">Cholesky</h3>
$$ A = LL^T$$<p>
Where, $L$ is a lower triangular matrix.</p>
<p><strong>Note</strong>: Cholesky decomposition is used as a test for positive definiteness of a matrix. If Cholesky decomposition succeeds, the matrix is positive definite, otherwise it is not. Another widely reported test for positive definiteness is to check the signs of all eigenvalues of the matrix. If all the eigenvalues are positive, the matrix is positive definite. But this method requires computation of all eigenvalues which is computationally nontrivial. Therefore, Cholesky decomposition is the preferred method to test for positive definiteness. If the matrix is not positive definite, Cholesky decomposition will stop at an intermediate step. On the other hand, if it succeeds, along with verifying positive definiteness of the matrix, we will get the Cholesky factor as a byproduct. Cholesky factor can then be used to solve linear systems as we will see later.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">14</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">L</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">L</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 0., 0.],
       [1., 2., 0.],
       [1., 2., 3.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">L</span><span class="p">,</span><span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[ 1.,  1.,  1.],
       [ 1.,  5.,  5.],
       [ 1.,  5., 14.]], dtype=float32)&gt;
</code></pre>
<p><a id = "qr"></a></p>
<h3 id="qr">QR</h3>
<p>Given a matrix $A$, $QR$ decomposition decomposes the matrix into an orthogonal matrix $Q$ and an upper triangular matrix $R$ such that product of $Q$ and $R$ gives back $A$. Columns of $Q$ are an orthogonal basis for the column space of $A$ (also known as range of $A$).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mf">5.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">Q</span><span class="p">,</span><span class="n">R</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Q:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">Q</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;R:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Q:
tf.Tensor(
[[-0.18257415  0.4079837 ]
 [-0.36514837 -0.44398218]
 [-0.5477225  -0.575977  ]
 [-0.73029673  0.5519779 ]], shape=(4, 2), dtype=float32)

R:
tf.Tensor(
[[-5.477226  -4.7469287]
 [ 0.         2.7778888]], shape=(2, 2), dtype=float32)
</code></pre>
<p>We can also get full $Q$ and $R$ matrices by setting <code>full_matrices = True</code> in the argument.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">Q_full</span><span class="p">,</span> <span class="n">R_full</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Q full:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">Q_full</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;R full:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">R_full</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Q full:
tf.Tensor(
[[-0.18257415  0.4079837  -0.17102492 -0.8780469 ]
 [-0.36514837 -0.44398218 -0.81774735  0.02891004]
 [-0.5477225  -0.575977    0.54808205 -0.2604928 ]
 [-0.73029673  0.5519779   0.04056833  0.4004264 ]], shape=(4, 4), dtype=float32)

R full:
tf.Tensor(
[[-5.477226  -4.7469287]
 [ 0.         2.7778888]
 [ 0.         0.       ]
 [ 0.         0.       ]], shape=(4, 2), dtype=float32)
</code></pre>
<p><a id = "svd"></a></p>
<h3 id="svd">SVD</h3>
$$A = U\Sigma V^T$$<p>
Where, $U\in R^{m\times m}$ and $V\in R^{n\times n}$ are orthogonal matrices, commonly known as left and right singular vectors respectively. $\Sigma \in R^{m\times n}$ is a diagonal matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mf">9.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">s</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;S:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;U:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;V:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>S:
tf.Tensor([18.604359   5.459675   2.4636664], shape=(3,), dtype=float32)

U:
tf.Tensor(
[[ 0.2936678   0.40458775  0.7340845 ]
 [ 0.48711583 -0.7956307   0.01849233]
 [ 0.34406567  0.418864   -0.67870086]
 [ 0.7470583   0.16683212  0.01195723]], shape=(4, 3), dtype=float32)

V:
tf.Tensor(
[[ 0.4678568   0.5231253   0.71235543]
 [ 0.6254436  -0.76545155  0.15134181]
 [ 0.62444425  0.3747316  -0.685307  ]], shape=(3, 3), dtype=float32)
</code></pre>
<p>The result is a truncated SVD. To get full SVD decomposition, we have to set <code>full_matrices = True</code> in the argument.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">s_full</span><span class="p">,</span><span class="n">u_full</span><span class="p">,</span><span class="n">v_full</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">full_matrices</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;S full:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">s_full</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;U full:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">u_full</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;V full:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">v_full</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>S full:
tf.Tensor([18.604359   5.459675   2.4636664], shape=(3,), dtype=float32)

U full:
tf.Tensor(
[[ 0.2936678   0.40458775  0.7340845  -0.45955172]
 [ 0.48711583 -0.7956307   0.01849233 -0.35964906]
 [ 0.34406567  0.418864   -0.67870086 -0.4955166 ]
 [ 0.7470583   0.16683212  0.01195723  0.6433724 ]], shape=(4, 4), dtype=float32)

V full:
tf.Tensor(
[[ 0.4678568   0.5231253   0.71235543]
 [ 0.6254436  -0.76545155  0.15134181]
 [ 0.62444425  0.3747316  -0.685307  ]], shape=(3, 3), dtype=float32)
</code></pre>
<p>If only singular values are of interest, it can be computed without computing singular vectors. In this way, computations can be much faster.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">mat</span><span class="p">,</span> <span class="n">compute_uv</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([18.604359 ,  5.459675 ,  2.4636664], dtype=float32)
</code></pre>
<p><a id = "eigenvalues_and_eigenvectors"></a></p>
<h2 id="eigenvalues-and-eigenvectors">Eigenvalues and eigenvectors</h2>
<p>Symmetry is an important consideration while computing eigenvalues and eigenvectors. For symmetric matrices, different set of algorithms are used for eigen analysis that exploit the symmetry of the matrix. Therefore, two functions are available in <code>tensorflow</code> for eigen analysis. <code>eig</code> is used to compute eigenvalues and eigenvectors of a dense matrix without any special structure. <code>eigh</code> is used for eigen analysis of <code>Hermitian</code> matrices. If only eigenvalues are of interest, <code>eigvals</code> and <code>eigvalsh</code> can be used compute just eigenvalues.</p>
<p><a id = "eigen-analysis_of_hermitian_matrices"></a></p>
<h3 id="eigen-analysis-of-hermitian-matrices">Eigen-analysis of Hermitian matrices</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">2.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">values</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigh</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Eigenvalues:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Eigenvectors:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span></code></pre></div><pre><code>Eigenvalues:
[1.        1.5857866 4.4142137]

Eigenvectors:
[[ 0.         -0.7071068   0.70710665]
 [-0.70710677  0.49999994  0.50000006]
 [ 0.7071068   0.4999999   0.5       ]]
</code></pre>
<p>Each row is an eigenvector.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matvec</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">vectors</span><span class="p">[</span><span class="mi">0</span><span class="p">,:])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([-1.7881393e-07, -7.0710701e-01,  7.0710647e-01], dtype=float32)
</code></pre>
<p>Results are accurate up to 5 decimal digits.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvalsh</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>    <span class="c1"># Just eigenvalues</span>
</span></span></code></pre></div><pre><code>array([1.       , 1.5857866, 4.4142137], dtype=float32)
</code></pre>
<h4 id="what-happens-if-you-pass-a-nonsymmetric-matrix-to-eigh-by-mistake">What happens if you pass a nonsymmetric matrix to <code>eigh</code> by mistake?</h4>
<p>Well, while using <code>eigh</code>, <code>tensorflow</code> assumes the matrix to be symmetric. <code>Tensorflow</code> doesn&rsquo;t check whether the matrix is symmetric or not. It just takes the lower triangular part, assumes that the upper triangular part is same because of symmetry and performs the computations. So be prepared to get a wrong result!</p>
<p><a id = "eigen-analysis_of_non-Hermitian_matrices"></a></p>
<h3 id="eigen-analysis-of-non-hermitian-matrices">Eigen-analysis of non-Hermitian matrices</h3>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">7</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="o">-</span><span class="mf">2.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">values</span><span class="p">,</span> <span class="n">vectors</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Eigenvalues:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">values</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Eigenvectors:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">vectors</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span></code></pre></div><pre><code>Eigenvalues:
[2.7560833 -7.9942424e-08j 0.12195918-7.5705280e+00j
 0.12195931+7.5705280e+00j]

Eigenvectors:
[[ 0.06142625+0.95019215j  0.16093381-0.34744066j  0.13818482+0.35709903j]
 [-0.01236177-0.19122148j  0.3560446 +0.53046155j  0.38952374-0.5063876j ]
 [ 0.01535368+0.23750281j -0.33046415+0.5796737j  -0.29238018-0.59978485j]]
</code></pre>
<p>Only eigenvalues.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eigvals</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([2.7560833 -7.9942424e-08j, 0.12195918-7.5705280e+00j,
       0.12195931+7.5705280e+00j], dtype=complex64)
</code></pre>
<h4 id="what-happens-when-you-pass-a-symmetric-matrix-to-eig">What happens when you pass a symmetric matrix to <code>eig</code>?</h4>
<p>Nothing! We will still get the correct answer. <code>Tensorflow</code> will use more operations to compute results when it could have been done using less computations.</p>
<p><a id = "solving_dense_linear_systems"></a></p>
<h2 id="solving-dense-linear-systems">Solving dense linear systems</h2>
$$ Ax = b$$<p>In general, $A$ can be square or rectangular. In our case, it is dense, i.e., most of its entries are nonzero. Right hand side $b$ is a vector in this case. If we have to solve the linear system for multiple right hand side vectors involving same $A$, the RHS can be replaced by a matrix whose columns are different RHS vectors.</p>
<p>Depending on the structure of $A$ (whether triangular, or tri-diagonal, or positive definite), suitable algorithm is chosen to solve the linear system. <code>Tensorflow</code> has a function <code>tf.linalg.solve</code> to solve linear systems. But this function doesn&rsquo;t take into account the special structure of $A$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">13</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[1.   ],
       [0.875],
       [1.125]], dtype=float32)&gt;
</code></pre>
<p><a id = "using_lu_decomposition"></a></p>
<h3 id="using-lu-decomposition">Using LU decomposition</h3>
<p>If $LU$ decomposition factors of $A$ are known, those can be used to solve the linear system.
For example, solve:

$$\begin{pmatrix}
  1 & 1 & 1\\
  1 & 5 & 5\\
  1 & 5 & 13
 \end{pmatrix} x= 
 \begin{pmatrix}
 3\\
 11\\
 20\\
 \end{pmatrix}$$
 
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">13</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">lu</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>   <span class="c1"># Factorization result of LU</span>
</span></span><span class="line"><span class="cl"><span class="n">x_sol_lu</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lu_solve</span><span class="p">(</span><span class="n">lu</span><span class="p">,</span><span class="n">p</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_sol_lu</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[1.   ],
       [0.875],
       [1.125]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">x_sol_lu</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[ 3.],
       [11.],
       [20.]], dtype=float32)&gt;
</code></pre>
$$Ly = b$$$$Ux = y$$<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">L</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">band_part</span><span class="p">(</span><span class="n">lu</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag_part</span><span class="p">(</span><span class="n">lu</span><span class="p">))</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="n">lu</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span>
</span></span><span class="line"><span class="cl"><span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">triangular_solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span><span class="n">b</span><span class="p">)</span>    <span class="c1"># Solves Ly = b</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">triangular_solve</span><span class="p">(</span><span class="n">lu</span><span class="p">,</span><span class="n">y</span><span class="p">,</span> <span class="n">lower</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>  <span class="c1"># Solves Ux = y</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[1.   ],
       [0.875],
       [1.125]], dtype=float32)&gt;
</code></pre>
<p><a id = "using_cholesky_decomposition"></a></p>
<h3 id="using-cholesky-decomposition">Using Cholesky decomposition</h3>
$$ LL^Tx = b$$$$ Ly = b$$$$L^Tx = y$$<p>In <code>tensorflow</code>, we solve the system using <code>tf.linalg.cholesky_solve</code>. It takes cholesky factor $(L)$ and right hand side $b$ as input.</p>
<p>For example, solve:

$$\begin{pmatrix}
  1 & 1 & 1\\
  1 & 5 & 5\\
  1 & 5 & 13
 \end{pmatrix} x= 
 \begin{pmatrix}
 3\\
 11\\
 20\\
 \end{pmatrix}$$
 
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">13</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">20</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">L</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sol_chol</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cholesky_solve</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">sol_chol</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[1.0000001],
       [0.8750001],
       [1.1249999]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">sol_chol</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[ 3.      ],
       [11.      ],
       [19.999998]], dtype=float32)&gt;
</code></pre>
<p><a id = "solving_structured_linear_systems"></a></p>
<h2 id="solving-structured-linear-systems">Solving structured linear systems</h2>
<p>If coefficient matrix of a linear system has some kind of structure (triangular, banded, tridiagonal, etc.), it can be efficiently solved using far fewer computations than required by dense $LU$ decomposition. Special solvers exist that exploit the structure of the coefficient matrix thus reducing flop count considerably for large structured systems. Linear algebra library of <code>Tensorflow</code> implements three such specialized solvers: <code>Triangular solver</code>, <code>Tridiagonal solver</code>, and <code>Banded triangular solver</code>.</p>
<p>Structured solvers have immensely useful as in many practical applications resulting coefficient matrix has some kind of structure. This is especially true in mechanical applications, such as finite element modeling, computational heat transfer, etc. In finite element modeling, a body is divided into several elements and each element has certain number of nodes. A node is connected to only a few neighboring nodes. So interaction of a node is limited to only those neighboring nodes. This results in banded systems. Other types of structured matrices are also common in applications.</p>
<p><a id = "solving_triangular_systems"></a></p>
<h2 id="solving-triangular-systems">Solving triangular systems</h2>
<p>We have already used triangular solvers in the section on <a href="#using_lu_decomposition">LU decomposition</a>. For completeness, we will again describe it in this section. <code>tf.linalg.triangular_solve</code> solves both <code>lower triangular</code> and <code>upper triangular</code> systems. Following examples demonstrate that.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">lower_triangular_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                    <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">rhs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">7</span><span class="p">],[</span><span class="mi">8</span><span class="p">],[</span><span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">res_lower_triangular</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">triangular_solve</span><span class="p">(</span><span class="n">matrix</span> <span class="o">=</span> <span class="n">lower_triangular_mat</span><span class="p">,</span> <span class="n">rhs</span> <span class="o">=</span> <span class="n">rhs</span><span class="p">,</span> <span class="n">lower</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">res_lower_triangular</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[ 7. ],
       [-2. ],
       [-1.5]], dtype=float32)&gt;
</code></pre>
<p>We can use the same solver to solve upper triangular system also. This is done by setting <code>adjoint = True</code> along with <code>lower = True</code>. <code>lower = True</code> extracts the lower triangular part of the coefficient matrix and <code>adjoint = True</code> solves the triangular system by transposing the extracted lower triangular part. For real matrices adjoint is same as transpose. By setting the arguments as above, essentially we solve the upper triangular system.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">res_upper_triangular</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">triangular_solve</span><span class="p">(</span><span class="n">matrix</span> <span class="o">=</span> <span class="n">lower_triangular_mat</span><span class="p">,</span> <span class="n">rhs</span> <span class="o">=</span> <span class="n">rhs</span><span class="p">,</span> <span class="n">lower</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">adjoint</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">res_upper_triangular</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[0.6666665 ],
       [0.16666667],
       [1.5       ]], dtype=float32)&gt;
</code></pre>
<p>We can verity the above result by multiplying the transpose of the lower triangular matrix by <code>res_upper_triangular</code>. This indeed gives us the right hand side $([7,8,9]^T)$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">lower_triangular_mat</span><span class="p">,</span> <span class="n">res_upper_triangular</span><span class="p">,</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[7.],
       [8.],
       [9.]], dtype=float32)&gt;
</code></pre>
<p><a id = "solving_tri-diagonal_systems"></a></p>
<h3 id="solving-tri-diagonal-systems">Solving tri-diagonal systems</h3>
<p>If matrix $A$ is tri-diagonal, <code>tf.linalg.tridiagonal_solve</code> can be used to solve the linear system efficiently. For example, we will solve the following tri-diagonal system.

$$\begin{pmatrix}
2 & -1 & 0 &0 & 0\\
-1 & 2 & -1 & 0 & 0\\
0 & -1 & 2& -1& 0\\
0 & 0 & -1 & 2 & -1\\
0 & 0 & 0 & -1 & 2
\end{pmatrix}x=
\begin{pmatrix}
3\\
4\\
-5\\
7\\
9\end{pmatrix}$$

</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">diags</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span> <span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mf">9.</span><span class="p">],</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tridiagonal_solve</span><span class="p">(</span><span class="n">diagonals</span> <span class="o">=</span> <span class="n">diags</span><span class="p">,</span> <span class="n">rhs</span> <span class="o">=</span> <span class="n">b</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
array([[ 6.5000005],
       [10.000001 ],
       [ 9.500001 ],
       [14.       ],
       [11.5      ]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">tridiagonal_matmul</span><span class="p">(</span><span class="n">diagonals</span><span class="o">=</span><span class="n">diags</span><span class="p">,</span> <span class="n">rhs</span> <span class="o">=</span> <span class="n">x</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
array([[ 3.      ],
       [ 4.000001],
       [-4.999999],
       [ 7.      ],
       [ 9.      ]], dtype=float32)&gt;
</code></pre>
<p><a id = "solving_banded_triangular_systems"></a></p>
<h3 id="solving-banded-triangular-systems">Solving banded triangular systems</h3>
<p>Solving an $(n \times n)$ full upper triangular (or lower triangular) system uses $n^2$ flops (including addition/subtraction and multiplication/division). But if the upper triangular (or lower triangular) system is banded with, say, $k$ bands (including main diagonal), the system can be solved in $\approx(2k-1)n$ flops. If $k$ is not very large, banded triangular systems can be solved at a fraction of computational cost as compared to dense triangular systems.</p>
<p>However, please keep in mind that flop count is not the only criteria that determines the computational time of a system. For very very large systems, communication time between different parts of computer can be significant as compared to processing required number of flops for that system.</p>
<p>We can solve both <code>banded lower triangular</code> and <code>banded upper triangular</code> systems. To illustrate this we will use the following example.

$$\begin{pmatrix}
1 & 0 & 0 & 0 & 0\\
6 & 2 & 0 & 0 & 0\\
0 & 7 & 3 & 0 & 0\\
0 & 0 & 8 & 4 & 0\\
0 & 0 & 0 & 9 & 5
\end{pmatrix}x=
\begin{pmatrix}
3\\
4\\
-5\\
7\\
9\end{pmatrix}$$

</p>
<p>As the matrix is banded, we need not create the full dense matrix. Instead, we can only pass the band part to the solver. Subdiagonals (or superdiagonals) contain less number of entries than main diagonal. While passing the band part to <code>tensorflow</code>, these subdiagonals (or superdiagonals) have to be appended either at left or right to make it of the same length as main diagonal. Whether the subdiagonals or superdiagonals will be appended at the left or right, is decided by the alignment strategy. There are four types of <code>alignment strategies</code> used in <code>tensorflow</code>. Those are:</p>
<ul>
<li><code>LEFT_LEFT</code>: Superdiagonals are <code>appended at right</code> and subdiagonals are <code>appended at right</code>.</li>
<li><code>LEFT_RIGHT</code>: Superdiagonals are <code>appended at right</code> and subdiagonals are <code>appended at left</code>.</li>
<li><code>RIGHT_LEFT</code>: Superdiagonals are <code>appended at left</code> and subdiagonals are <code>appended at right</code>.</li>
<li><code>RIGHT_RIGHT</code>: Superdiagonals are <code>appended at left</code> and subdiagonals are <code>appended at left</code>.</li>
</ul>
<p>One way to remember the above rules is that if something is aligned to left, it is appended at right. And in <code>LEFT_RIGHT</code>, first word corresponds to superdiagonals and second word corresponds to subdiagonal. For <code>tf.linalg.banded_triangular_solve</code>, <code>tensorflow</code> assumes that input band part has <code>LEFT_RIGHT</code> alignment. Band part inputs to this function can be modified accordingly. Above problem can be solved as follows.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">bands</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Because of LEFT_RIGHT alignment as we have a subdiagonal here</span>
</span></span><span class="line"><span class="cl"><span class="n">rhs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">4</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">7</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">banded_lower_triangular_sol</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">banded_triangular_solve</span><span class="p">(</span><span class="n">bands</span> <span class="o">=</span> <span class="n">bands</span><span class="p">,</span> <span class="n">rhs</span> <span class="o">=</span> <span class="n">rhs</span><span class="p">,</span> <span class="n">lower</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">banded_lower_triangular_sol</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
array([[  3.      ],
       [ -7.      ],
       [ 14.666667],
       [-27.583334],
       [ 51.45    ]], dtype=float32)&gt;
</code></pre>
<p>We can verify the above solution by multiplying the dense banded lower triangular matrix by the solution. This should give us the RHS.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dense_banded_lower_triangular_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">set_diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)),</span> <span class="n">diagonal</span> <span class="o">=</span> <span class="n">bands</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                       <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="n">align</span> <span class="o">=</span> <span class="s2">&#34;LEFT_RIGHT&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dense_banded_lower_triangular_mat</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 0., 0., 0., 0.],
       [6., 2., 0., 0., 0.],
       [0., 7., 3., 0., 0.],
       [0., 0., 8., 4., 0.],
       [0., 0., 0., 9., 5.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dense_banded_lower_triangular_mat</span><span class="p">,</span> <span class="n">banded_lower_triangular_sol</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
array([[ 3.],
       [ 4.],
       [-5.],
       [ 7.],
       [ 9.]], dtype=float32)&gt;
</code></pre>
<p>Similarly we can solve banded upper triangular matrix. For illustration, we will use the transpose of the above coefficient matrix. We will use the same right hand side vector.

$$\begin{pmatrix}
1 & 6 & 0 & 0 & 0\\
0 & 2 & 7 & 0 & 0\\
0 & 0 & 3 & 8 & 0\\
0 & 0 & 0 & 4 & 9\\
0 & 0 & 0 & 0 & 5
\end{pmatrix}x=
\begin{pmatrix}
3\\
4\\
-5\\
7\\
9\end{pmatrix}$$

</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">bands</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># Because of LEFT_RIGHT alignment as we have a superdiagonal here</span>
</span></span><span class="line"><span class="cl"><span class="n">rhs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">4</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">7</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">banded_upper_triangular_sol</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">banded_triangular_solve</span><span class="p">(</span><span class="n">bands</span> <span class="o">=</span> <span class="n">bands</span><span class="p">,</span> <span class="n">rhs</span> <span class="o">=</span> <span class="n">rhs</span><span class="p">,</span> <span class="n">lower</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">banded_upper_triangular_sol</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
array([[ 84.79998  ],
       [-13.63333  ],
       [  4.4666657],
       [ -2.2999997],
       [  1.8      ]], dtype=float32)&gt;
</code></pre>
<p>Now we will verify the solution.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">dense_banded_upper_triangular_mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">set_diag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">)),</span> <span class="n">diagonal</span> <span class="o">=</span> <span class="n">bands</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                                       <span class="n">k</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">align</span> <span class="o">=</span> <span class="s2">&#34;LEFT_RIGHT&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">dense_banded_upper_triangular_mat</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 6., 0., 0., 0.],
       [0., 2., 7., 0., 0.],
       [0., 0., 3., 8., 0.],
       [0., 0., 0., 4., 9.],
       [0., 0., 0., 0., 5.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">dense_banded_upper_triangular_mat</span><span class="p">,</span> <span class="n">banded_upper_triangular_sol</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 1), dtype=float32, numpy=
array([[ 3.],
       [ 4.],
       [-5.],
       [ 7.],
       [ 9.]], dtype=float32)&gt;
</code></pre>
<p><a id = "solving_least_squares_problems"></a></p>
<h2 id="solving-least-squares-problems">Solving least squares problems</h2>
<p><a id = "ordinary_least_squares"></a></p>
<h3 id="ordinary-least-squares">Ordinary least squares</h3>
<p>Both over determined and under determined least squares problem can be solved using the command <code>tf.linalg.lstsq</code>. In the underdetermined case, the output is the least norm solution. Least squares problem can be written as</p>

$$\underset{x}{\mathrm{argmin}}{\lVert{Ax-b}\rVert}_2^2$$


<p>That is, we try to find an $x$ such that the residual error is as small as possible.
For example, we will solve following two problems.

$$\begin{pmatrix}
1 & 2\\
2 & 0.5\\
3 & 1\\
4 & 5\\
\end{pmatrix}x_{over}=
\begin{pmatrix}
3\\
4\\
5\\
6\\
\end{pmatrix}$$
$$\begin{pmatrix}
3 & 1 & 2 & 5\\
7 & 9 & 1 & 4
\end{pmatrix}x_{under}=
\begin{pmatrix}
7.2\\
-5.8\\
\end{pmatrix}$$

</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A_over</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mf">5.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">A_under</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">4.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">b_over</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">6.</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">b_under</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">7.2</span><span class="p">,</span><span class="o">-</span><span class="mf">5.8</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x_over</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">A_over</span><span class="p">,</span> <span class="n">b_over</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_over</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[ 1.704103  ],
       [-0.04319588]], dtype=float32)&gt;
</code></pre>
<p>Though it is not advisable, for this simple case, we will directly apply normal equation to get the solution ($(A^TA)^{-1}A^Tb$).</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A_over</span><span class="p">,</span><span class="n">A_over</span><span class="p">,</span> <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)),</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A_over</span><span class="p">,</span><span class="n">b_over</span><span class="p">,</span> <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[ 1.704104  ],
       [-0.04319668]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x_under</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">A_under</span><span class="p">,</span> <span class="n">b_under</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_under</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 1), dtype=float32, numpy=
array([[-0.04100358],
       [-1.3355565 ],
       [ 0.699703  ],
       [ 1.4518324 ]], dtype=float32)&gt;
</code></pre>
<p>We will computer the least norm solution for underdetermined case using the closed form solution ($A^T(AA^T)^{-1}b$). However, it should be remembered that it is not advisable to do so in practice for large systems. The closed form solution can be obtained by applying Lagrange multipliers.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A_under</span><span class="p">,</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">A_under</span><span class="p">,</span> <span class="n">A_under</span><span class="p">,</span> <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)),</span> <span class="n">b_under</span><span class="p">),</span> <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 1), dtype=float32, numpy=
array([[-0.04100358],
       [-1.3355561 ],
       [ 0.6997029 ],
       [ 1.4518325 ]], dtype=float32)&gt;
</code></pre>
<p><a id = "regularized_least_squares"></a></p>
<h3 id="regularized-least-squares">Regularized least squares</h3>
<p>Only $l_2$ regularization is supported. The following regularized problem is solved.</p>
$$\underset{x}{\mathrm{argmin}}{\lVert{Ax-b}\rVert}_2^2 + \lambda {\lVert{x}\rVert}_2^2$$<p>Here, $\lambda$ is a hyperparameter. Usually several values of $\lambda$ are tried over a logarithmic scale before choosing the best one.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x_over_reg</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">A_over</span><span class="p">,</span> <span class="n">b_over</span><span class="p">,</span> <span class="n">l2_regularizer</span><span class="o">=</span> <span class="mf">2.0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_over_reg</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[1.3890449 ],
       [0.21348318]], dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x_under_reg</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">A_under</span><span class="p">,</span> <span class="n">b_under</span><span class="p">,</span> <span class="n">l2_regularizer</span><span class="o">=</span><span class="mf">2.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_under_reg</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 1), dtype=float32, numpy=
array([[-0.04763567],
       [-1.214508  ],
       [ 0.62748903],
       [ 1.299031  ]], dtype=float32)&gt;
</code></pre>
<p><a id = "some_specialized_operations"></a></p>
<h2 id="some-specialized-operations">Some specialized operations</h2>
<p><a id = "norm"></a></p>
<h3 id="norm">Norm</h3>
<p>Norm can be defined for vectors as well as matrices. $p$ norm of vector is defined as

$${\lVert{x}\rVert}_p = (\Sigma_{i=1}^{n}|x_i|^p)^\frac{1}{p}$$

</p>
<p>Matrix is norm is defined as

$${\lVert{A}\rVert}_p= \max_{x\neq 0}\frac{{\lVert{Ax}\rVert}_p}{{\lVert{x}\rVert}_p}$$

</p>
<p><code>Tensorflow</code> supports all the usual vector and matrix norms that are used in practice. Using only <code>tensorflow</code> we can calculate all norms except <code>infinity</code> norm. To calculate <code>infinity</code> norm we have to use <code>ord = np.inf</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.</span><span class="p">]),</span> <span class="nb">ord</span> <span class="o">=</span> <span class="s2">&#34;euclidean&#34;</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>3.7416575
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]),</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>6
</code></pre>
<p>Fractional norms for <strong>vectors</strong> are also supported.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mf">3.</span><span class="p">]),</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mf">0.75</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>8.46176
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">8.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">mat_norm_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;2 norm of matrix A = &#34;</span><span class="p">,</span> <span class="n">mat_norm_2</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span></code></pre></div><pre><code>WARNING:tensorflow:From /home/biswajit/anaconda3/envs/tf_cpu_23/lib/python3.8/site-packages/tensorflow/python/ops/linalg_ops.py:735: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.
Instructions for updating:
This op will be removed after the deprecation date. Please switch to tf.sets.difference().
2 norm of matrix A =  15.294547
</code></pre>
<p>2 norm of a matrix is equivalent to the largest singular value of the matrix. We will verify that.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">vals</span><span class="p">,</span><span class="n">_</span> <span class="p">,</span><span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">vals</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>15.294547
</code></pre>
<p><a id = "normalizing_a_tensor"></a></p>
<h3 id="normalizing-a-tensor">Normalizing a tensor</h3>
<p>Computes the norm and normalizes the tensor using that norm. By normalize we mean, divide the entries of the tensor by the norm. Here, we will consider a matrix. But the method can be extended to multi-dimensional tensor.</p>
<p>If computed norm is a single number, all the entries of the matrix will be divided by that number. If norm is calculated along some axis, normalization happens along that axis using individual norms. Here are some examples.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy=
array([[1., 8., 2., 3.],
       [2., 7., 6., 5.],
       [0., 3., 2., 8.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">normalized_mat</span><span class="p">,</span> <span class="n">norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Normalized matrix: &#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">normalized_mat</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Norm = &#34;</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span></code></pre></div><pre><code>Normalized matrix: 
[[0.06538278 0.5230622  0.13076556 0.19614834]
 [0.13076556 0.45767945 0.39229667 0.3269139 ]
 [0.         0.19614834 0.13076556 0.5230622 ]]

Norm =  [[15.294547]]
</code></pre>
<p>We will get the same normalized matrix by dividing the entries of the matrix by the norm.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span><span class="o">/</span><span class="n">norm</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy=
array([[0.06538278, 0.5230622 , 0.13076556, 0.19614834],
       [0.13076556, 0.45767945, 0.39229667, 0.3269139 ],
       [0.        , 0.19614834, 0.13076556, 0.5230622 ]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">norm_mat_by_col</span><span class="p">,</span> <span class="n">norms_col</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Normalized matrix:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">norm_mat_by_col</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Norms of columns of A:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">norms_col</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Normalized matrix:
tf.Tensor(
[[0.4472136  0.724286   0.30151135 0.30304575]
 [0.8944272  0.63375026 0.904534   0.5050763 ]
 [0.         0.27160725 0.30151135 0.80812204]], shape=(3, 4), dtype=float32)

Norms of columns of A:
tf.Tensor([[ 2.236068  11.045361   6.6332498  9.899495 ]], shape=(1, 4), dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>  <span class="c1"># 2 Norm of first column of A</span>
</span></span></code></pre></div><pre><code>2.236068
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span><span class="o">/</span><span class="n">norms_col</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy=
array([[0.4472136 , 0.724286  , 0.30151135, 0.30304575],
       [0.8944272 , 0.63375026, 0.904534  , 0.5050763 ],
       [0.        , 0.27160725, 0.30151135, 0.80812204]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">norm_mat_by_row</span><span class="p">,</span> <span class="n">norms_row</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Normalized matrix:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">norm_mat_by_row</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Norms of rows:&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">norms_row</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>Normalized matrix:
tf.Tensor(
[[0.11322771 0.9058217  0.22645542 0.33968312]
 [0.18731716 0.6556101  0.56195146 0.4682929 ]
 [0.         0.34188172 0.22792116 0.91168463]], shape=(3, 4), dtype=float32)

Norms of rows:
tf.Tensor(
[[ 8.83176 ]
 [10.677078]
 [ 8.774964]], shape=(3, 1), dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="mi">0</span><span class="p">,:],</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>    <span class="c1"># 2 norm of first row of A</span>
</span></span></code></pre></div><pre><code>8.83176
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span><span class="o">/</span><span class="n">norms_row</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy=
array([[0.11322771, 0.9058217 , 0.22645542, 0.33968312],
       [0.18731716, 0.6556101 , 0.56195146, 0.4682929 ],
       [0.        , 0.34188172, 0.22792116, 0.91168463]], dtype=float32)&gt;
</code></pre>
<p><a id = "global_norm"></a></p>
<h3 id="global-norm">Global norm</h3>
<p>Given two or more tensors, <code>tf.linalg.global_norm</code> computes the 2 norm of a vector generated by resizing all the tensors to one dimensional arrays.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mf">3.</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="mf">7.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">global_norm</span><span class="p">([</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>11.83216
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mf">7.</span><span class="p">],</span> <span class="nb">ord</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>11.83216
</code></pre>
<p><a id = "cross_product_of_vectors"></a></p>
<h3 id="cross-product-of-vectors">Cross product of vectors</h3>
<p>It is defined for 3-element vectors. For two vectors $a = (a_1, a_2, a_3)^T$, and $b = (b_1, b_2, b_3)^T$, cross product is defined as the determinant of following matrix

$$\begin{pmatrix}
i & j & k\\
a_1 & a_2 & a_3\\
b_1 & b_2 & b_3
\end{pmatrix}$$


Where $i, j$, and $k$ are unit direction vectors along three perpendicular right handed system.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">a</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([-1,  2, -1], dtype=int32)
</code></pre>
<p>First element in the output corresponds to the value along $i$th direction. Similarly for other outputs.</p>
<p>It is also possible to calculate cross product of more that one pair of vectors simultaneously.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">c</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">cross</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="n">d</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[-0.8989703 , -0.89722276,  0.05096105],
       [-0.44832098, -0.32573706, -0.11998086],
       [ 0.7280822 ,  0.19632304,  0.8862282 ],
       [ 0.0998309 ,  0.48842978, -0.03491247],
       [ 1.0497653 , -1.5643073 ,  0.5671499 ]], dtype=float32)
</code></pre>
<p>First row of output is the cross product of first rows of $c$ and $d$. Similarly for other rows.</p>
<p><a id = "matrix_square_root"></a></p>
<h3 id="matrix-square-root">Matrix square root</h3>
<p>Square root of a matrix is defined for invertible matrices whose real eigenvalues are positive.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">6.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">mat_root</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">sqrtm</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mat_root</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[2.1185937 , 0.35412252, 0.6189322 ],
       [0.30147368, 2.9409115 , 0.7257953 ],
       [0.6540313 , 0.33657336, 2.3132057 ]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">mat_root</span><span class="p">,</span> <span class="n">mat_root</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[4.9999986, 2.0000007, 3.0000038],
       [2.0000005, 9.000003 , 4.0000057],
       [3.0000033, 2.000003 , 6.0000052]], dtype=float32)&gt;
</code></pre>
<p><a id = "matrix_exponential"></a></p>
<h3 id="matrix-exponential">Matrix exponential</h3>
<p>Exponential of a matrix $A$ is defined as</p>
$$ e^A = \sum_{n=0}^\infty \frac{A^n}{n!}$$<p>In practice, the sum is not taken to infinity. Rather, approximations are used to compute matrix exponential. <code>Tensorflow</code> implementation is based on <a href="https://epubs.siam.org/doi/10.1137/04061101X" target="_blank" rel="noopener">this paper</a>.</p>
$$e^A = Se^{\Lambda}S^{-1}$$<p>where, $S$ is the eigenvector matrix and $e^\Lambda$ is a diagonal matrix whose diagonal entries are exponentials of eigenvalues of the matrix $A$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mf">0.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">expm</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=
array([[1.5430806, 1.1752012],
       [1.1752012, 1.5430806]], dtype=float32)&gt;
</code></pre>
<p><a id = "matrix_logarithm"></a></p>
<h3 id="matrix-logarithm">Matrix logarithm</h3>
<p>Computes logarithm of the matrix such that matrix exponential of the result gives back the original matrix. Refer to the <a href="https://www.tensorflow.org/api_docs/python/tf/linalg/logm" target="_blank" rel="noopener">documentation</a> for further details. It is defined only for complex matrices.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">6.</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">complex64</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mat_log</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">logm</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">mat_log</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=complex64, numpy=
array([[1.4031177 +0.j, 0.25731087+0.j, 0.53848237+0.j],
       [0.16580153+0.j, 2.1160111 +0.j, 0.54512537+0.j],
       [0.5994888 +0.j, 0.2268081 +0.j, 1.5622762 +0.j]], dtype=complex64)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">expm</span><span class="p">(</span><span class="n">mat_log</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=complex64, numpy=
array([[4.999999 +0.j, 1.9999989+0.j, 2.9999986+0.j],
       [1.9999995+0.j, 9.000006 +0.j, 4.0000005+0.j],
       [2.9999995+0.j, 2.000001 +0.j, 5.9999995+0.j]], dtype=complex64)&gt;
</code></pre>
<p><a id = "log-determinant_of_a_matrix"></a></p>
<h3 id="log-determinant-of-a-matrix">Log-determinant of a matrix</h3>
<p>Computes the natural logarithm of the determinant of a matrix. There are two functions in <code>tensorflow </code> to calculate this.</p>
<ul>
<li>If matrix is symmetric positive definite, use <code>tf.linalg.logdet</code> (Uses Cholesky decomposition)</li>
<li>For other matrices, use <code>tf.linalg.slogdet</code> (Uses $LU$ decomposition)</li>
</ul>
<p><code>slogdet</code> computes the sign of the determinant as well as the log of the absolute value of the determinant.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mf">6.</span><span class="p">]])</span>   <span class="c1"># Symmetric positive definite</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">logdet</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>5.1298985
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">mat</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>5.1298985
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                     <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">6.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">sign</span><span class="p">,</span> <span class="n">log_abs_det</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">slogdet</span><span class="p">(</span><span class="n">mat_2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Sign of determinant = &#34;</span><span class="p">,</span> <span class="n">sign</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Log of absolute value of determinant = &#34;</span><span class="p">,</span> <span class="n">log_abs_det</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span></code></pre></div><pre><code>Sign of determinant =  -1.0
Log of absolute value of determinant =  4.0943446
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">det</span><span class="p">(</span><span class="n">mat_2</span><span class="p">)))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>4.0943446
</code></pre>
<p><a id = "pseudo_inverse_of_a_matrix"></a></p>
<h3 id="pseudo-inverse-of-a-matrix">Pseudo inverse of a matrix</h3>
<p>While matrix inverse is defined only for square matrices, pseudo inverse is defined for matrices of any shape. It is also defined for singular matrices. Pseudo inverse can also be used to solve ordinary least squares problem. For the problem</p>
$$\underset{x}{\mathrm{argmin}}{\lVert {Ax-b} \rVert}_2^2$$<p>the approximate least squares solution can be written as</p>
$$x_{ls} = A^{\dagger}b$$<p>Where, $A^{\dagger}$ is the pseudo inverse of $A$.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">0</span><span class="p">],[</span><span class="mi">5</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mf">0.</span><span class="p">]]))</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[0.06896552, 0.        , 0.17241378],
       [0.        , 0.33333334, 0.        ],
       [0.        , 0.        , 0.        ]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A_over</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mf">5.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">A_under</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mf">4.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">b_over</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mf">6.</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">b_under</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mf">7.2</span><span class="p">,</span><span class="o">-</span><span class="mf">5.8</span><span class="p">],</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x_ls_over</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">A_over</span><span class="p">,</span><span class="n">b_over</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_ls_over</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[ 1.704103  ],
       [-0.04319588]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">A_over</span><span class="p">),</span><span class="n">b_over</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 1), dtype=float32, numpy=
array([[ 1.7041038 ],
       [-0.04319668]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">x_ls_under</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">lstsq</span><span class="p">(</span><span class="n">A_under</span><span class="p">,</span> <span class="n">b_under</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">x_ls_under</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 1), dtype=float32, numpy=
array([[-0.04100358],
       [-1.3355565 ],
       [ 0.699703  ],
       [ 1.4518324 ]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">pinv</span><span class="p">(</span><span class="n">A_under</span><span class="p">),</span> <span class="n">b_under</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 1), dtype=float32, numpy=
array([[-0.04100376],
       [-1.3355565 ],
       [ 0.69970286],
       [ 1.4518324 ]], dtype=float32)&gt;
</code></pre>
<p><a id = "linear_operators"></a></p>
<h2 id="linear-operators">Linear operators</h2>
<p>Linear operators are a powerful way of defining matrices and associated operators without even doing actual computations. What does this mean? Do we ever get result of our computations using operators? Well, the computations are done only when we ask for the results. Before that the operators just act on each other (like chaining of operators) without doing any computation. We will show this by examples.</p>
<p><strong>Note</strong>: We will mainly use operators to form dense matrices. But the scope of applicability of operators is far bigger than that.</p>
<p>To define a matrix as an operator, we use <code>tf.linalg.LinearOperatorFullMatrix</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                           <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                           <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mf">9.</span><span class="p">]]))</span>
</span></span><span class="line"><span class="cl"><span class="n">operator</span>
</span></span></code></pre></div><pre><code>&lt;tensorflow.python.ops.linalg.linear_operator_full_matrix.LinearOperatorFullMatrix at 0x7f8f501e7580&gt;
</code></pre>
<p>We get only the memory location. No result is shown. To see the actual matrix we have to call the method <code>to_dense</code> on this operator. There are many methods that can be called on an operator. For the full list, refer the documentation.</p>
<p>Before seeing the result, we will apply adjoint operator to our old operator and apply <code>to_dense</code> to the adjoint operator. If everything works well, we should see the transpose of the matrix as result.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">adj_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorAdjoint</span><span class="p">(</span><span class="n">operator</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">adj_operator</span>
</span></span></code></pre></div><pre><code>WARNING:tensorflow:From /home/biswajit/anaconda3/envs/tf_cpu_23/lib/python3.8/site-packages/tensorflow/python/ops/linalg/linear_operator_adjoint.py:145: LinearOperator.graph_parents (from tensorflow.python.ops.linalg.linear_operator) is deprecated and will be removed in a future version.
Instructions for updating:
Do not call `graph_parents`.





&lt;tensorflow.python.ops.linalg.linear_operator_adjoint.LinearOperatorAdjoint at 0x7f8f501e71f0&gt;
</code></pre>
<p>Again no result. At this point we want to see the result. So we will apply <code>to_dense</code> method to adj_operator.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">adj_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 2., 7.],
       [2., 3., 8.],
       [3., 5., 9.]], dtype=float32)&gt;
</code></pre>
<p>To compare it with our original matrix, we will also show the original matrix.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 2., 3.],
       [2., 3., 5.],
       [7., 8., 9.]], dtype=float32)&gt;
</code></pre>
<p>As expected, the adjoint operator gives the correct answer.</p>
<p><a id = "common_methods_on_linear_operators"></a></p>
<h3 id="common-methods-on-linear-operators">Common methods on linear operators</h3>
<p>There are many methods that can be called on the operator. Depending on the operator, the methods vary. In this section we will discuss some of the methods of <code>LinearOperatorFullMatrix</code> operator. Some of the methods are:</p>
<ul>
<li>cond (To find condition number)</li>
<li>determinant</li>
<li>cholesky (To compute Cholesky factors of operator)</li>
<li>eigvals (Compute eigenvalues only for self-adjoint (Hermitian) matrices)</li>
<li>trace</li>
<li>inverse</li>
<li>solve (Solve linear system using operator)</li>
<li>adjoint</li>
</ul>
<p>and many others.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 2., 3.],
       [2., 3., 5.],
       [7., 8., 9.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">cond</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(), dtype=float32, numpy=68.21983&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">trace</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(), dtype=float32, numpy=13.0&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">determinant</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>WARNING:tensorflow:Using (possibly slow) default implementation of determinant.  Requires conversion to a dense matrix and O(N^3) operations.





&lt;tf.Tensor: shape=(), dtype=float32, numpy=6.0&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">adjoint</span><span class="p">()</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 2., 7.],
       [2., 3., 8.],
       [3., 5., 9.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[-2.1666667 ,  1.        ,  0.16666669],
       [ 2.8333333 , -2.        ,  0.16666669],
       [-0.83333325,  1.        , -0.16666669]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">operator</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span><span class="o">.</span><span class="n">to_dense</span><span class="p">())</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[ 1.0000000e+00,  0.0000000e+00,  0.0000000e+00],
       [-2.3841858e-07,  1.0000000e+00,  0.0000000e+00],
       [-2.3841858e-07,  0.0000000e+00,  1.0000000e+00]], dtype=float32)&gt;
</code></pre>
<p><a id = "special_matrices_using_operators"></a></p>
<h3 id="special-matrices-using-operators">Special matrices using operators</h3>
<p><a id = "toeplitz_matrix"></a></p>
<h4 id="toeplitz-matrix">Toeplitz matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">col</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mf">5.</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">row</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mf">9.</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">toeplitz_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorToeplitz</span><span class="p">(</span><span class="n">col</span> <span class="o">=</span> <span class="n">col</span><span class="p">,</span> <span class="n">row</span> <span class="o">=</span> <span class="n">row</span> <span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">toeplitz_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 6., 7., 8., 9.],
       [2., 1., 6., 7., 8.],
       [3., 2., 1., 6., 7.],
       [4., 3., 2., 1., 6.],
       [5., 4., 3., 2., 1.]], dtype=float32)&gt;
</code></pre>
<p><a id = "circulant_matrix"></a></p>
<h4 id="circulant-matrix">Circulant matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">kernel</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">spectrum</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">signal</span><span class="o">.</span><span class="n">fft</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">complex64</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">circ_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorCirculant</span><span class="p">(</span><span class="n">spectrum</span> <span class="o">=</span> <span class="n">spectrum</span><span class="p">,</span> <span class="n">input_output_dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">circ_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1.0000002 , 4.9999995 , 3.9999993 , 3.        , 2.0000005 ],
       [2.0000005 , 0.99999934, 4.9999995 , 3.9999993 , 2.9999998 ],
       [3.0000002 , 2.        , 0.9999998 , 4.9999995 , 3.9999998 ],
       [3.9999993 , 2.9999993 , 2.        , 1.        , 4.9999995 ],
       [4.9999995 , 3.9999993 , 3.        , 2.0000005 , 1.0000002 ]],
      dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">circ_operator</span><span class="o">.</span><span class="n">convolution_kernel</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5,), dtype=float32, numpy=
array([1.       , 2.0000002, 3.       , 3.9999993, 4.9999995],
      dtype=float32)&gt;
</code></pre>
<p><a id = "block_diagonal_matrix"></a></p>
<h4 id="block-diagonal-matrix">Block diagonal matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                             <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                             <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">operator_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                           <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">6</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">blk_diag_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorBlockDiag</span><span class="p">([</span><span class="n">operator_1</span><span class="p">,</span><span class="n">operator_2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">blk_diag_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 1.,  2.,  3.,  0.,  0.],
       [ 4.,  5.,  6.,  0.,  0.],
       [ 7.,  8.,  9.,  0.,  0.],
       [ 0.,  0.,  0., -9., -8.],
       [ 0.,  0.,  0., -7., -6.]], dtype=float32)&gt;
</code></pre>
<p><a id = "block_lower_triangular_matrix"></a></p>
<h4 id="block-lower-triangular-matrix">Block lower triangular matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator_3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mf">6.</span><span class="p">,</span><span class="n">repeats</span> <span class="o">=</span> <span class="mi">6</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="n">blk_lower</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorBlockLowerTriangular</span><span class="p">([[</span><span class="n">operator_1</span><span class="p">],</span> <span class="p">[</span><span class="n">operator_3</span><span class="p">,</span> <span class="n">operator_2</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">blk_lower</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 1.,  2.,  3.,  0.,  0.],
       [ 4.,  5.,  6.,  0.,  0.],
       [ 7.,  8.,  9.,  0.,  0.],
       [ 6.,  6.,  6., -9., -8.],
       [ 6.,  6.,  6., -7., -6.]], dtype=float32)&gt;
</code></pre>
<p><a id = "householder_matrix"></a></p>
<h4 id="householder-matrix">Householder matrix</h4>
<p>Householder matrix can be used to triangularize a matrix using orthogonal matrices (the process is called orthogonal triangularization). But we will not pursue that point here. We will only show the method using only a column vector. Given a vector $v = [1, 4, 7]^T$, Householder transform can transform the vector into $v = {\lVert{v}\rVert}_2[1,0,0]^T$. It is achieved by multiplying the vector $v$ by an orthogonal Householder matrix $H$.

$$H\begin{pmatrix}
v_1\\
v_2\\
v_3\end{pmatrix}={\lVert{v}\rVert}_2\begin{pmatrix}
1\\
0\\
0\end{pmatrix}$$

</p>
<p>This process can be repeated with other columns of a matrix to transform it into an upper triangular one. For more details, have a look at the references.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">first_column_of_operator_1</span> <span class="o">=</span> <span class="n">operator_1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()[:,</span><span class="mi">0</span><span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="n">norm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">first_column_of_operator_1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">vec</span> <span class="o">=</span> <span class="n">first_column_of_operator_1</span> <span class="o">-</span> <span class="n">norm</span><span class="o">*</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">)[:,</span><span class="mi">0</span><span class="p">]</span>    <span class="c1"># Whether to take positive or negative sign? See references.</span>
</span></span><span class="line"><span class="cl"><span class="n">householder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorHouseholder</span><span class="p">(</span><span class="n">reflection_axis</span> <span class="o">=</span> <span class="n">vec</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">householder</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">first_column_of_operator_1</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([[8.1240387e+00],
       [4.7683716e-07],
       [4.7683716e-07]], dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">householder</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">first_column_of_operator_1</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">)))</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 1), dtype=float32, numpy=
array([[8.1240387e+00],
       [4.7683716e-07],
       [7.1525574e-07]], dtype=float32)&gt;
</code></pre>
<p><a id = "kronecker_matrix"></a></p>
<h4 id="kronecker-matrix">Kronecker matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator_1</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 2., 3.],
       [4., 5., 6.],
       [7., 8., 9.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator_2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=
array([[-9., -8.],
       [-7., -6.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">kron_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorKronecker</span><span class="p">([</span><span class="n">operator_1</span><span class="p">,</span><span class="n">operator_2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">kron_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(6, 6), dtype=float32, numpy=
array([[ -9.,  -8., -18., -16., -27., -24.],
       [ -7.,  -6., -14., -12., -21., -18.],
       [-36., -32., -45., -40., -54., -48.],
       [-28., -24., -35., -30., -42., -36.],
       [-63., -56., -72., -64., -81., -72.],
       [-49., -42., -56., -48., -63., -54.]], dtype=float32)&gt;
</code></pre>
<p><a id = "permutation_matrix"></a></p>
<h4 id="permutation-matrix">Permutation matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">perm_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorPermutation</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl"><span class="n">perm_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[0., 0., 1., 0., 0.],
       [0., 0., 0., 0., 1.],
       [1., 0., 0., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 1., 0., 0., 0.]], dtype=float32)&gt;
</code></pre>
<p><a id = "common_matrices_using_operators"></a></p>
<h3 id="common-matrices-using-operators">Common matrices using operators</h3>
<p><a id = "identity_matrix"></a></p>
<h4 id="identity-matrix-1">Identity matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">iden_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorIdentity</span><span class="p">(</span><span class="n">num_rows</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">iden_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 1.]], dtype=float32)&gt;
</code></pre>
<p><a id = "scaled_identity_matrix"></a></p>
<h4 id="scaled-identity-matrix">Scaled identity matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">scaled_iden_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorScaledIdentity</span><span class="p">(</span><span class="n">num_rows</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">multiplier</span> <span class="o">=</span> <span class="mf">5.</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">scaled_iden_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[5., 0., 0., 0., 0.],
       [0., 5., 0., 0., 0.],
       [0., 0., 5., 0., 0.],
       [0., 0., 0., 5., 0.],
       [0., 0., 0., 0., 5.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">scaled_iden_operator_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorScaledIdentity</span><span class="p">(</span><span class="n">num_rows</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">multiplier</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl"><span class="n">scaled_iden_operator_2</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=
array([[[-5,  0,  0],
        [ 0, -5,  0],
        [ 0,  0, -5]],

       [[ 7,  0,  0],
        [ 0,  7,  0],
        [ 0,  0,  7]]], dtype=int32)&gt;
</code></pre>
<p><a id = "diagonal_matrix"></a></p>
<h4 id="diagonal-matrix-1">Diagonal matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">diag_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorDiag</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mf">4.</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl"><span class="n">diag_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[1., 0., 0., 0.],
       [0., 2., 0., 0.],
       [0., 0., 3., 0.],
       [0., 0., 0., 4.]], dtype=float32)&gt;
</code></pre>
<p><a id = "tri-diagonal_matrix"></a></p>
<h4 id="tri-diagonal-matrix-1">Tri-diagonal matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">diags</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span> <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                         <span class="p">[</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">tridiag_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorTridiag</span><span class="p">(</span><span class="n">diagonals</span> <span class="o">=</span> <span class="n">diags</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">tridiag_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=
array([[ 2., -1.,  0.,  0.,  0.],
       [-1.,  2., -1.,  0.,  0.],
       [ 0., -1.,  2., -1.,  0.],
       [ 0.,  0., -1.,  2., -1.],
       [ 0.,  0.,  0., -1.,  2.]], dtype=float32)&gt;
</code></pre>
<p><a id = "lower_triangular_matrix"></a></p>
<h4 id="lower-triangular-matrix">Lower triangular matrix</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">mat</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                   <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">lower_tri_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorLowerTriangular</span><span class="p">(</span><span class="n">mat</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">lower_tri_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 4), dtype=float32, numpy=
array([[2., 0., 0., 0.],
       [1., 2., 0., 0.],
       [5., 8., 9., 0.],
       [4., 2., 3., 1.]], dtype=float32)&gt;
</code></pre>
<p><a id = "matrix_of_zeros"></a></p>
<h4 id="matrix-of-zeros">Matrix of zeros</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">zeros_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorZeros</span><span class="p">(</span><span class="n">num_rows</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="n">num_columns</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">is_square</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="n">is_self_adjoint</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">zeros_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(4, 5), dtype=float32, numpy=
array([[0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.],
       [0., 0., 0., 0., 0.]], dtype=float32)&gt;
</code></pre>
<p><a id = "matrix_operations_using_operators"></a></p>
<h3 id="matrix-operations-using-operators">Matrix operations using operators</h3>
<p><a id = "low-rank_update"></a></p>
<h4 id="low-rank-update">Low-rank update</h4>
<p>When a low rank matrix is added to a given matrix, the resulting matrix is called a low-rank update of the original matrix. Let&rsquo;s suppose our original matrix was $A$ and we add a rank 1 update to it. The resulting matrix is $B$. So</p>
$$B = A + uv^T$$<p>Where, $u$, and $v$ are column vectors. It should be noted that low-rank matrix update doesn&rsquo;t always increase the rank of the original matrix. For example, if rank of $A$ was 2, updating it with a rank 1 matrix will not always  make its rank 3. Here is an example.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">A</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">u</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">6</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">7</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">v</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">([[</span><span class="mi">7</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">8</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                 <span class="p">[</span><span class="mi">9</span><span class="p">]],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">B</span> <span class="o">=</span> <span class="n">A</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">u</span><span class="p">,</span><span class="n">v</span><span class="p">,</span> <span class="n">transpose_b</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Rank of A = &#34;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">A</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Rank of B = &#34;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">matrix_rank</span><span class="p">(</span><span class="n">B</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</span></span></code></pre></div><pre><code>Rank of A =  2
Rank of B =  2
</code></pre>
<p><strong>Why is it useful?</strong></p>
<p>It turns out that this low rank update appears in many applications. One of the applications is in least squares. Imagine that you have solved the least squares problem using the available data. And now you get some new data. The problem is to get the new least squares fit. Well, you can start form scratch by including the new data to your old data and then fit the model on the whole data. But this is a wasteful approach. A better alternative is to use the new data to modify your old fit. If you do some mathematics, you will arrive at matrix update equation. We will not do the math here. Interested readers can check references.</p>
<p>Computations can be much faster if we use low-rank matrix update equation. In tensorflow it is done using <code>tf.linalg.OperatorLowRankUpdate</code> operator. Though the operator can handle more than rank 1 update, we will use it only for rank 1 update.</p>
$$B^{-1} = (A+uv^T)^{-1} = A^{-1}-\frac{A^{-1}uv^TA^{-1}}{1+v^TA^{-1}u}$$<p>Provided that the denominator is not equal to zero. Note that denominator is a scalar for rank 1 update. This equation show that we can compute new inverse from the old inverse by using matrix-vector and vector-vector multiplications.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 2., 3.],
       [2., 3., 5.],
       [7., 8., 9.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">low_rank_update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorLowRankUpdate</span><span class="p">(</span><span class="n">operator</span><span class="p">,</span><span class="n">u</span> <span class="o">=</span> <span class="n">u</span><span class="p">,</span> <span class="n">diag_update</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">low_rank_update</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[-2.1666667 ,  1.        ,  0.625     ],
       [ 2.8333333 , -2.        , -0.24999982],
       [-0.83333325,  1.        , -0.25000012]], dtype=float32)&gt;
</code></pre>
<p>Using Sherman–Morrison-Woodbury formula.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator_inv</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">second_factor_numer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">operator_inv</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">operator_inv</span><span class="o">.</span><span class="n">to_dense</span><span class="p">(),</span> <span class="n">transpose_a</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">second_factor_denom</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">operator_inv</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">transpose_a</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">update_inv</span> <span class="o">=</span> <span class="n">operator</span><span class="o">.</span><span class="n">inverse</span><span class="p">()</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">second_factor_denom</span><span class="p">)</span><span class="o">*</span><span class="n">second_factor_numer</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="n">update_inv</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>tf.Tensor(
[[-2.1666667   1.          0.6250001 ]
 [ 2.8333333  -2.         -0.25      ]
 [-0.83333325  1.         -0.25000006]], shape=(3, 3), dtype=float32)
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">low_rank_update</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[36., 42., 48.],
       [44., 51., 59.],
       [56., 64., 72.]], dtype=float32)&gt;
</code></pre>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">transpose_b</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[36., 42., 48.],
       [44., 51., 59.],
       [56., 64., 72.]], dtype=float32)&gt;
</code></pre>
<p>Along with inverse, other methods can be applied to <code>LinearOperatorLowRankUpdate</code>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">low_rank_update</span><span class="o">.</span><span class="n">diag_part</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>array([36., 51., 72.], dtype=float32)
</code></pre>
<p><a id = "operator_inversion"></a></p>
<h4 id="operator-inversion">Operator inversion</h4>
<p>Computes inverse operator of a given operator.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">inv_operator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorInversion</span><span class="p">(</span><span class="n">operator</span> <span class="o">=</span> <span class="n">operator</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">inv_operator</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[-2.1666667 ,  1.        ,  0.16666669],
       [ 2.8333333 , -2.        ,  0.16666669],
       [-0.83333325,  1.        , -0.16666669]], dtype=float32)&gt;
</code></pre>
<p><a id = "operator_composition"></a></p>
<h4 id="operator-composition">Operator composition</h4>
<p>Like composition of function, this operator applies one operator over another. In terms of matrices, it just means matrix multiplication. But the result of composition is another operator. That new operator can be used for further analysis.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">operator_1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                 <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                 <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="o">-</span><span class="mf">3.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">operator_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorFullMatrix</span><span class="p">([[</span><span class="mi">2</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span>
</span></span><span class="line"><span class="cl">                                                 <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mf">5.</span><span class="p">]])</span>
</span></span><span class="line"><span class="cl"><span class="n">operator_comp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">LinearOperatorComposition</span><span class="p">([</span><span class="n">operator_1</span><span class="p">,</span><span class="n">operator_2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="n">operator_comp</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span>
</span></span></code></pre></div><pre><code>&lt;tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[  0.,   7.,  13.],
       [ -1.,  18.,  31.],
       [ 17., -19.,   6.]], dtype=float32)&gt;
</code></pre>
<p><a id = "conclusion"></a></p>
<h2 id="conclusion">Conclusion</h2>
<p>As we have seen, using only <code>tensorflow</code> we can do quite a bit of linear algebra. In this post, we have only glossed over some of the functionalities. Clever use of the functions and operators will enable us to do much more than what has been covered here. At times, it might feel a little verbose. But the flexibility that it offers will make the exploration a rewarding experience.</p>
<h2 id="references">References</h2>
<ol>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/linalg" target="_blank" rel="noopener">Tensorflow documentation</a></li>
<li>Datta, Biswa Nath. Numerical linear algebra and applications. Vol. 116. Siam, 2010.</li>
<li>(The Book) Golub, Gene H., and Charles F. Van Loan. Matrix computations. Vol. 3. JHU press, 2012.</li>
</ol>
<p>Last updated: 30 July, 2020.</p>

      </div>

      
  <time class="mt-12 mb-8 block text-xs text-gray-500 ltr:text-right rtl:text-left dark:text-gray-400" datetime="2020-05-14T00:00:00.000Z">
    <span>Last updated on</span>
    May 14, 2020</time>

      <div class="container mx-auto prose prose-slate lg:prose-xl dark:prose-invert mt-5">
        
        <div class="max-w-prose print:hidden">
  
  

  

<div class="flex justify-center">
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/linear-algebra/">Linear Algebra</a>
  
  <a class="no-underline bg-primary-100 hover:bg-primary-300 text-primary-800 text-xs font-medium mr-2 px-2.5 py-0.5 lg:px-5 lg:py-2 rounded dark:bg-primary-900 dark:hover:bg-primary-700 dark:text-primary-300" href="/tags/tensorflow/">Tensorflow</a>
  
</div>


  
<section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://twitter.com/intent/tweet?url=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fdoing-linear-algebra-using-tensorflow-2%2F&amp;text=Doing&#43;Linear&#43;Algebra&#43;using&#43;Tensorflow&#43;2"
    title="X"
    aria-label="X"
    id="share-link-x"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://www.facebook.com/sharer.php?u=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fdoing-linear-algebra-using-tensorflow-2%2F&amp;t=Doing&#43;Linear&#43;Algebra&#43;using&#43;Tensorflow&#43;2"
    title="Facebook"
    aria-label="Facebook"
    id="share-link-facebook"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="currentColor" d="M22 12c0-5.52-4.48-10-10-10S2 6.48 2 12c0 4.84 3.44 8.87 8 9.8V15H8v-3h2V9.5C10 7.57 11.57 6 13.5 6H16v3h-2c-.55 0-1 .45-1 1v2h3v3h-3v6.95c5.05-.5 9-4.76 9-9.95z"/></svg>
  </a>
  

  
  
  
  
  
  
    
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="mailto:?subject=Doing%20Linear%20Algebra%20using%20Tensorflow%202&amp;body=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fdoing-linear-algebra-using-tensorflow-2%2F"
    title="Email"
    aria-label="Email"
    id="share-link-email"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-width="1.5" d="M16.5 12a4.5 4.5 0 1 1-9 0a4.5 4.5 0 0 1 9 0Zm0 0c0 1.657 1.007 3 2.25 3S21 13.657 21 12a9 9 0 1 0-2.636 6.364M16.5 12V8.25"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="https://www.linkedin.com/shareArticle?url=http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fdoing-linear-algebra-using-tensorflow-2%2F&amp;title=Doing&#43;Linear&#43;Algebra&#43;using&#43;Tensorflow&#43;2"
    title="LinkedIn"
    aria-label="LinkedIn"
    id="share-link-linkedin"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
  </a>
  

  
  
  
  
  
  
  <a
    target="_blank" rel="noopener"
    class="m-1 rounded-md bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral-300 dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
    href="whatsapp://send?text=Doing&#43;Linear&#43;Algebra&#43;using&#43;Tensorflow&#43;2%20http%3A%2F%2Flocalhost%3A1313%2Fpost%2Fdoing-linear-algebra-using-tensorflow-2%2F"
    title="WhatsApp"
    aria-label="WhatsApp"
    id="share-link-whatsapp"
  >
    <svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 256" fill="currentColor"><path d="m187.58 144.84-32-16a8 8 0 0 0-8 .5l-14.69 9.8a40.55 40.55 0 0 1-16-16l9.8-14.69a8 8 0 0 0 .5-8l-16-32A8 8 0 0 0 104 64a40 40 0 0 0-40 40 88.1 88.1 0 0 0 88 88 40 40 0 0 0 40-40 8 8 0 0 0-4.42-7.16ZM152 176a72.08 72.08 0 0 1-72-72 24 24 0 0 1 19.29-23.54l11.48 23L101 118a8 8 0 0 0-.73 7.51 56.47 56.47 0 0 0 30.15 30.15A8 8 0 0 0 138 155l14.61-9.74 23 11.48A24 24 0 0 1 152 176ZM128 24a104 104 0 0 0-91.82 152.88l-11.35 34.05a16 16 0 0 0 20.24 20.24l34.05-11.35A104 104 0 1 0 128 24Zm0 192a87.87 87.87 0 0 1-44.06-11.81 8 8 0 0 0-6.54-.67L40 216l12.47-37.4a8 8 0 0 0-.66-6.54A88 88 0 1 1 128 216Z"/></svg>
  </a>
  
</section>


  








  
  



  
  
  
    
  
  
  

<div class="flex pt-12 pb-4">
  
  
  <img
    class="mr-4 h-24 w-24 rounded-full"
    width="96"
    height="96"
    alt="Biswajit Sahoo"
  src="/author/biswajit-sahoo/avatar_hu13253178770287002488.jpg"
  loading="lazy"
  />
  
  <div class="place-self-center">
    <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
      Authors
    </div>
    <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
      <a href="http://localhost:1313/" class="no-underline">
      Biswajit Sahoo
      </a>
    </div>

    
    <div class="text-sm font-bold text-neutral-700 dark:text-neutral-300">
    Machine Learning Engineer
    </div>
    


    
    <div class="text-sm text-neutral-700 dark:text-neutral-300">My research interests include machine learning, deep learning, signal processing and data-driven machinery condition monitoring.</div>
    

    <div class="text-2xl sm:text-lg pt-1">

      
<div class="flex flex-wrap text-neutral-500 dark:text-neutral-300">
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="/#contact"
      
      aria-label="Envelope"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="1.5" d="M21.75 6.75v10.5a2.25 2.25 0 0 1-2.25 2.25h-15a2.25 2.25 0 0 1-2.25-2.25V6.75m19.5 0A2.25 2.25 0 0 0 19.5 4.5h-15a2.25 2.25 0 0 0-2.25 2.25m19.5 0v.243a2.25 2.25 0 0 1-1.07 1.916l-7.5 4.615a2.25 2.25 0 0 1-2.36 0L3.32 8.91a2.25 2.25 0 0 1-1.07-1.916V6.75"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://github.com/biswajitsahoo1111"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/Github"
    ><svg style="height: 1em;" fill="currentColor" viewBox="3 3 18 18"><path d="M12 3C7.0275 3 3 7.12937 3 12.2276C3 16.3109 5.57625 19.7597 9.15374 20.9824C9.60374 21.0631 9.77249 20.7863 9.77249 20.5441C9.77249 20.3249 9.76125 19.5982 9.76125 18.8254C7.5 19.2522 6.915 18.2602 6.735 17.7412C6.63375 17.4759 6.19499 16.6569 5.8125 16.4378C5.4975 16.2647 5.0475 15.838 5.80124 15.8264C6.51 15.8149 7.01625 16.4954 7.18499 16.7723C7.99499 18.1679 9.28875 17.7758 9.80625 17.5335C9.885 16.9337 10.1212 16.53 10.38 16.2993C8.3775 16.0687 6.285 15.2728 6.285 11.7432C6.285 10.7397 6.63375 9.9092 7.20749 9.26326C7.1175 9.03257 6.8025 8.08674 7.2975 6.81794C7.2975 6.81794 8.05125 6.57571 9.77249 7.76377C10.4925 7.55615 11.2575 7.45234 12.0225 7.45234C12.7875 7.45234 13.5525 7.55615 14.2725 7.76377C15.9937 6.56418 16.7475 6.81794 16.7475 6.81794C17.2424 8.08674 16.9275 9.03257 16.8375 9.26326C17.4113 9.9092 17.76 10.7281 17.76 11.7432C17.76 15.2843 15.6563 16.0687 13.6537 16.2993C13.98 16.5877 14.2613 17.1414 14.2613 18.0065C14.2613 19.2407 14.25 20.2326 14.25 20.5441C14.25 20.7863 14.4188 21.0746 14.8688 20.9824C16.6554 20.364 18.2079 19.1866 19.3078 17.6162C20.4077 16.0457 20.9995 14.1611 21 12.2276C21 7.12937 16.9725 3 12 3Z"></path></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://www.linkedin.com/in/biswajitsahoo1111/"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Brands/Linkedin"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" height="1em" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg></a>
  
    
    
    
    
      
    
    <a
      class="pr-2 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
      style="will-change:transform;"
      href="https://scholar.google.co.in/citations?hl=en&amp;user=zu2CSBMAAAAJ"
      target="_blank" rel="noopener" rel="me noopener noreferrer"
      aria-label="Academicons/Google-Scholar"
    ><svg style="height: 1em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M343.759 106.662V79.43L363.524 64h-213.89L20.476 176.274h85.656a82.339 82.339 0 0 0-.219 6.225c0 20.845 7.22 38.087 21.672 51.861c14.453 13.797 32.252 20.648 53.327 20.648c4.923 0 9.75-.368 14.438-1.024c-2.907 6.5-4.374 12.523-4.374 18.142c0 9.875 4.499 20.43 13.467 31.642c-39.234 2.67-68.061 9.732-86.437 21.163c-10.531 6.5-19 14.704-25.39 24.531c-6.391 9.9-9.578 20.515-9.578 31.962c0 9.648 2.062 18.336 6.219 26.062c4.156 7.726 9.578 14.07 16.312 18.984c6.718 4.968 14.469 9.101 23.219 12.469c8.734 3.344 17.406 5.718 26.061 7.062A167.052 167.052 0 0 0 180.555 448c13.469 0 26.953-1.734 40.547-5.187c13.562-3.485 26.28-8.642 38.171-15.493c11.86-6.805 21.515-16.086 28.922-27.718c7.39-11.68 11.094-24.805 11.094-39.336c0-11.016-2.25-21.039-6.75-30.14c-4.468-9.073-9.938-16.542-16.452-22.345c-6.501-5.813-13-11.155-19.516-15.968c-6.5-4.845-12-9.75-16.468-14.813c-4.485-5.046-6.735-10.054-6.735-14.984c0-4.921 1.734-9.672 5.216-14.265c3.455-4.61 7.674-9.048 12.61-13.306c4.937-4.25 9.875-8.968 14.796-14.133c4.922-5.147 9.141-11.827 12.61-20.008c3.485-8.18 5.203-17.445 5.203-27.757c0-13.453-2.547-24.46-7.547-33.314c-.594-1.022-1.218-1.803-1.875-3.022l56.907-46.672v17.119c-7.393.93-6.624 5.345-6.624 10.635V245.96c0 5.958 4.875 10.834 10.834 10.834h3.989c5.958 0 10.833-4.875 10.833-10.834V117.293c0-5.277.778-9.688-6.561-10.63zm-107.36 222.48c1.14.75 3.704 2.78 7.718 6.038c4.05 3.243 6.797 5.695 8.266 7.414a443.553 443.553 0 0 1 6.376 7.547c2.813 3.375 4.718 6.304 5.718 8.734c1 2.477 2.016 5.461 3.047 8.946a38.27 38.27 0 0 1 1.485 10.562c0 17.048-6.564 29.68-19.656 37.859c-13.125 8.18-28.767 12.274-46.938 12.274c-9.187 0-18.203-1.093-27.063-3.196c-8.843-2.116-17.311-5.336-25.39-9.601c-8.078-4.258-14.577-10.204-19.5-17.797c-4.938-7.64-7.407-16.415-7.407-26.25c0-10.32 2.797-19.29 8.422-26.906c5.594-7.625 12.938-13.391 22.032-17.315c9.063-3.946 18.25-6.742 27.562-8.398a157.865 157.865 0 0 1 28.438-2.555c4.47 0 7.936.25 10.405.696c.455.219 3.032 2.07 7.735 5.563c4.704 3.462 7.625 5.595 8.75 6.384zm-3.359-100.579c-7.406 8.86-17.734 13.288-30.953 13.288c-11.86 0-22.298-4.764-31.266-14.312c-9-9.523-15.422-20.328-19.344-32.43c-3.937-12.109-5.906-23.984-5.906-35.648c0-13.694 3.596-25.352 10.781-34.976c7.187-9.65 17.5-14.485 30.938-14.485c11.875 0 22.374 5.038 31.437 15.157c9.094 10.085 15.61 21.413 19.517 33.968c3.922 12.54 5.873 24.53 5.873 35.984c0 13.446-3.702 24.61-11.076 33.454z"/></svg></a>
  
</div>



    </div>
  </div>
</div>







  
  
    
    
    
      
      
    
<div class="pt-1 no-prose w-full">
  <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
  <div class="flex flex-col md:flex-row flex-nowrap justify-between gap-5 pt-2">
    <div class="">
      
        <a class="group flex no-underline" href="/post/efficiently-reading-multiple-files-in-tensorflow-2/">
          <span
            class="mt-[-0.3rem] me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
          ><span class="ltr:inline rtl:hidden">&larr;</span></span>
          <span class="flex flex-col">
            <span
              class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
            >Efficiently reading multiple files in Tensorflow 2</span>
            <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
              
                May 17, 2020
              
            </span>
          </span>
        </a>
      
    </div>
    <div class="">
      
        <a class="group flex text-right no-underline" href="/post/reading-multiple-files-in-tensorflow-2/">
          <span class="flex flex-col">
            <span
              class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
            >Reading multiple files in Tensorflow 2</span
            >
            <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
              
                Jan 9, 2020
              
            </span>
          </span>
          <span
            class="mt-[-0.3rem] ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
          ><span class="ltr:inline">&rarr;</span></span>
        </a>
      
    </div>
  </div>
</div>



  

  
  
<hr class="border-dotted border-neutral-300 dark:border-neutral-600">
  <div class="text-sm">
    <h3>Related</h3>
    <ul>
      
      <li><a href="/post/reading-multiple-files-in-tensorflow-2/">Reading multiple files in Tensorflow 2</a></li>
      
      <li><a href="/post/using-python-generators/">Using Python Generators</a></li>
      
      <li><a href="/post/revisiting-systems-of-linear-equations/">Revisiting Systems of Linear Equations</a></li>
      
    </ul>
  </div>
  


  


  
  
  

  

  
  <section id="comments">
    
  
  <script src="https://giscus.app/client.js"
          data-repo="biswajitsahoo1111/biswajitsahoo1111.github.io"
          data-repo-id="MDEwOlJlcG9zaXRvcnkxNzE5MzExMzM="
          data-category="General"
          data-category-id="DIC_kwDOCj91_c4CljPc"
          data-mapping="title"
          data-strict="0"
          data-reactions-enabled="1"
          data-emit-metadata="0"
          data-input-position="top"
          data-theme="preferred_color_scheme"
          data-lang="en"
          data-loading="lazy"
          crossorigin="anonymous"
          async>
  </script>


  </section>
  


</div>

      </div>

    </main>
  </article>
</div>

    </div>
    <div class="page-footer">
      <footer class="container mx-auto flex flex-col justify-items-center text-sm leading-6 mt-24 mb-4 text-slate-700 dark:text-slate-200">

    











  
    
    
    
    
    














  
  <p class="powered-by text-center">
    © 2024 Biswajit Sahoo. Powered by <a href="https://hugoblox.com/" target="_blank" rel="noopener">Hugo Blox Builder</a>.
  </p>
  




  
    <p class="powered-by text-center">
      
    </p>
  
  </footer>
    </div>

    
    











  </body>
</html>

<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Attention Mechanism | Biswajit Sahoo</title>
    <link>https://biswajitsahoo1111.github.io/tag/attention-mechanism/</link>
      <atom:link href="https://biswajitsahoo1111.github.io/tag/attention-mechanism/index.xml" rel="self" type="application/rss+xml" />
    <description>Attention Mechanism</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Â© 2023 Biswajit Sahoo</copyright><lastBuildDate>Thu, 01 Apr 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://biswajitsahoo1111.github.io/media/icon_hu9aa3fb3801987e3e09a10d02b6e0c908_114644_512x512_fill_lanczos_center_3.png</url>
      <title>Attention Mechanism</title>
      <link>https://biswajitsahoo1111.github.io/tag/attention-mechanism/</link>
    </image>
    
    <item>
      <title>IndexedSlices in Tensorflow</title>
      <link>https://biswajitsahoo1111.github.io/post/indexedslices-in-tensorflow/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://biswajitsahoo1111.github.io/post/indexedslices-in-tensorflow/</guid>
      <description>&lt;table class=&#34;tfo-notebook-buttons&#34; align=&#34;left&#34;&gt;
  &lt;td&gt;
    &lt;a href=&#34;https://colab.research.google.com/github/biswajitsahoo1111/blog_notebooks/blob/master/Tensorflow_IndexedSlices.ipynb&#34;&gt;
    &lt;img src=&#34;https://www.tensorflow.org/images/colab_logo_32px.png&#34; /&gt;
    Run in Google Colab&lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
    &lt;a href=&#34;https://github.com/biswajitsahoo1111/blog_notebooks/blob/master/Tensorflow_IndexedSlices.ipynb&#34;&gt;
    &lt;img src=&#34;https://www.tensorflow.org/images/GitHub-Mark-32px.png&#34; /&gt;
    View source on GitHub&lt;/a&gt;
  &lt;/td&gt;
  &lt;td&gt;
    &lt;a href=&#34;https://www.dropbox.com/s/paze6mubda9bvv4/Tensorflow_IndexedSlices.ipynb?dl=1&#34;&gt;&lt;img src=&#34;https://www.tensorflow.org/images/download_logo_32px.png&#34; /&gt;Download notebook&lt;/a&gt;
  &lt;/td&gt;
&lt;/table&gt;
&lt;p&gt;In this post, we will discuss about &lt;code&gt;IndexedSlices&lt;/code&gt; class of &lt;code&gt;Tensorflow&lt;/code&gt;. We will try to answer the following questions in this blog:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#q1&#34;&gt;What are &lt;code&gt;IndexedSlices&lt;/code&gt;?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#q2&#34;&gt;Where do we get it?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#q3&#34;&gt;How to convert from IndexedSlices to tensors?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id = &#34;q1&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-are-indexedslices&#34;&gt;What are &lt;code&gt;IndexedSlices&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;According to &lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/IndexedSlices&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;Tensorflow&lt;/code&gt; documentation&lt;/a&gt;, &lt;code&gt;IndexedSlices&lt;/code&gt; are sparse representation of a set of tensor slices at a given index. At an high level it appears to be some kind of sparse representation. Let&amp;rsquo;s try to understand it with examples.&lt;/p&gt;
&lt;p&gt;&lt;a id = &#34;q2&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;where-do-we-get-it&#34;&gt;Where do we get it?&lt;/h2&gt;
&lt;p&gt;We get &lt;code&gt;IndexedSlices&lt;/code&gt; while taking gradients of an &lt;code&gt;Embedding&lt;/code&gt; layer. Embedding matrices can be huge (depending on vocabulary size). But each batch only contains a small fraction of tokens. So while computing the gradient of loss with respect to embedding layer, in each pass we have to only consider the corresponding token embeedings of the present batch. Naturally a sparse tensor seems to be a better option to record those gradients. &lt;code&gt;Tensorflow&lt;/code&gt; does that using &lt;code&gt;IndexedSlices&lt;/code&gt;. We will show that below using a contrived example.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;import&lt;/span&gt; tensorflow &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tf
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;Tensorflow version: &amp;#34;&lt;/span&gt;, tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;__version__)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Tensorflow version:  2.4.0
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;models&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Sequential([
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Vocab size: 10, Embedding dimension: 4, Input_shape size: (batch_size, num_words). As usual, batch_size is omitted.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Embedding(&lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;4&lt;/span&gt;, input_shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;,)),
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Flatten(), 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;layers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;Dense(&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;summary()
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding (Embedding)        (None, 5, 4)              40        
_________________________________________________________________
flatten (Flatten)            (None, 20)                0         
_________________________________________________________________
dense (Dense)                (None, 1)                 21        
=================================================================
Total params: 61
Trainable params: 61
Non-trainable params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;random&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;uniform(shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;5&lt;/span&gt;), minval &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;, maxval &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;10&lt;/span&gt;, dtype &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;int32) &lt;span style=&#34;color:#75715e&#34;&gt;# Batch size is 1.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;data
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(1, 5), dtype=int32, numpy=array([[6, 1, 1, 4, 8]])&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;variables  &lt;span style=&#34;color:#75715e&#34;&gt;# Is a list of 3 tensors. 1 from Embedding layer and 2 from Dense layer (Kernel and bias)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;[&amp;lt;tf.Variable &#39;embedding/embeddings:0&#39; shape=(10, 4) dtype=float32, numpy=
 array([[ 4.10897247e-02, -2.48962641e-03,  1.26880072e-02,
          3.39310430e-02],
        [ 3.28579657e-02,  3.90318781e-03,  2.81411521e-02,
          3.09719704e-02],
        [ 1.16247907e-02, -1.41257644e-02, -3.36343870e-02,
         -4.41543460e-02],
        [-4.67238426e-02,  2.42819674e-02, -4.26802635e-02,
         -2.59207971e-02],
        [ 2.28367783e-02, -2.09717881e-02,  1.05572566e-02,
          3.33249308e-02],
        [-3.37148309e-02, -4.61939685e-02, -2.61853095e-02,
         -4.10162285e-03],
        [-3.59787717e-02,  2.78765075e-02, -3.16200405e-02,
          4.54976298e-02],
        [-4.67344411e-02, -1.30221620e-02,  1.52915232e-02,
          2.22466923e-02],
        [-1.03901625e-02,  2.40740217e-02, -1.24427900e-02,
          4.47194651e-03],
        [-3.57637033e-02,  4.28059734e-02, -2.59280205e-05,
          4.09286283e-02]], dtype=float32)&amp;gt;,
 &amp;lt;tf.Variable &#39;dense/kernel:0&#39; shape=(20, 1) dtype=float32, numpy=
 array([[ 0.42870212],
        [ 0.04779923],
        [ 0.4126016 ],
        [-0.13294601],
        [-0.3175783 ],
        [-0.46080017],
        [-0.23412797],
        [ 0.30137837],
        [-0.5197849 ],
        [-0.10935467],
        [ 0.5087845 ],
        [-0.06930307],
        [ 0.10028934],
        [-0.11278141],
        [-0.21269777],
        [-0.0214209 ],
        [ 0.12959635],
        [-0.13330323],
        [-0.23972857],
        [ 0.23718971]], dtype=float32)&amp;gt;,
 &amp;lt;tf.Variable &#39;dense/bias:0&#39; shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)&amp;gt;]
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;optimizer &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;optimizers&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;SGD(learning_rate &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0.1&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;loss_object &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;keras&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;losses&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;MeanSquaredError()
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;target &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;constant([&lt;span style=&#34;color:#ae81ff&#34;&gt;2.5&lt;/span&gt;], shape &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; (&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#ae81ff&#34;&gt;1&lt;/span&gt;))
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; _ &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; range(&lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;):   &lt;span style=&#34;color:#75715e&#34;&gt;# Let&amp;#39;s run gradient descent for two batches of the same input data. (It&amp;#39;s a contrived examples)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;GradientTape() &lt;span style=&#34;color:#66d9ef&#34;&gt;as&lt;/span&gt; tape:
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        output &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; model(data) &lt;span style=&#34;color:#75715e&#34;&gt;# Output has shape: (batch_size, 1). Here batch_size is 1. So output shape is (1,1)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        loss_value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; loss_object(target, output)  &lt;span style=&#34;color:#75715e&#34;&gt;# Calculating some random loss.&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    grads &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tape&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;gradient(loss_value, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable_variables)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Gradient descent step&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    optimizer&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;apply_gradients(zip(grads, model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;trainable_variables))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;len(grads)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;3
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;grads[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tensorflow.python.framework.indexed_slices.IndexedSlices at 0x16c04d4a970&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;print(grads[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;IndexedSlices(indices=tf.Tensor([6 1 1 4 8], shape=(5,), dtype=int32), values=tf.Tensor(
[[-0.9495101  -0.14344962 -0.91739434  0.25398374]
 [ 0.69607455  1.0615798   0.5085497  -0.7338184 ]
 [ 1.1639317   0.24842012 -1.2103697   0.12384857]
 [-0.25895947  0.2856651   0.47968888  0.01028775]
 [-0.28760925  0.28005898  0.56933826 -0.5540699 ]], shape=(5, 4), dtype=float32), dense_shape=tf.Tensor([10  4], shape=(2,), dtype=int32))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An &lt;code&gt;IndexedSlices&lt;/code&gt; object has 3 main entries.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;indices&lt;/li&gt;
&lt;li&gt;values, and&lt;/li&gt;
&lt;li&gt;dense_shape&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a id = &#34;q3&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;how-to-convert-indexedslices-to-tensors&#34;&gt;How to convert &lt;code&gt;IndexedSlices&lt;/code&gt; to &lt;code&gt;Tensors&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;Before we do the conversion, let&amp;rsquo;s answer a relevant question: Why do we have to do the conversion from &lt;code&gt;IndexedSlices&lt;/code&gt; to tensors given that &lt;code&gt;Tensorflow&lt;/code&gt; can do a gradient descent step automatically through the &lt;code&gt;IndexedSlices&lt;/code&gt;? In the last section, we could run 2 gradient descent steps without worrying about &lt;code&gt;IndexedSlices&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But the problem occurs if we want to do some processing on gradient values. One such processing is &lt;code&gt;gradient clipping&lt;/code&gt;. In &lt;code&gt;gradient clipping&lt;/code&gt;, if sum of norm of gradients exceed a given value, gradients are rescaled to decrease their magnitude. Therefore, to do any gradient clipping, we have to access the gradient tensors. This is precisely where we would like to convert IndexedSlices to tensors. Having an embedding layer is common in deep learning models and applying gradient clipping to gradient values is also a common practice. We will show two approaches to do the conversion.&lt;/p&gt;
&lt;h3 id=&#34;easiest-approach&#34;&gt;Easiest approach&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;convert_to_tensor(grads[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;&amp;lt;tf.Tensor: shape=(10, 4), dtype=float32, numpy=
array([[ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 1.8600063 ,  1.31      , -0.70182   , -0.60996985],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.25895947,  0.2856651 ,  0.47968888,  0.01028775],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.9495101 , -0.14344962, -0.91739434,  0.25398374],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.28760925,  0.28005898,  0.56933826, -0.5540699 ],
       [ 0.        ,  0.        ,  0.        ,  0.        ]],
      dtype=float32)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;what-did-just-happen-in-the-last-step&#34;&gt;What did just happen in the last step?&lt;/h3&gt;
&lt;p&gt;Though the last approach is a single line elegant solution, it hides many things. How actually is the conversion done? The code below shows the steps in which we can manually do the conversion.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;check_grad &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; tf&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;zeros_like(model&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;variables[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;])&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;numpy()   &lt;span style=&#34;color:#75715e&#34;&gt;# Create a dense tensor of all zeros&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;for&lt;/span&gt; i, ind &lt;span style=&#34;color:#f92672&#34;&gt;in&lt;/span&gt; enumerate(grads[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;indices):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    check_grad[ind] &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; check_grad[ind] &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt; grads[&lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;]&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;values[i]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;check_grad
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;pre&gt;&lt;code&gt;array([[ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 1.8600063 ,  1.31      , -0.70182   , -0.60996985],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.25895947,  0.2856651 ,  0.47968888,  0.01028775],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.9495101 , -0.14344962, -0.91739434,  0.25398374],
       [ 0.        ,  0.        ,  0.        ,  0.        ],
       [-0.28760925,  0.28005898,  0.56933826, -0.5540699 ],
       [ 0.        ,  0.        ,  0.        ,  0.        ]],
      dtype=float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This brings us to the end of this blog. I hope this blog has demystified a few things about &lt;code&gt;IndexedSlices&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Motivation for this post&lt;/strong&gt;: While writing TF 2 code for &lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Attention Mechanisms chapter of D2L book&lt;/a&gt;, the author encountered an error involving &lt;code&gt;IndexedSlices&lt;/code&gt;. After spending a good deal of time hopelessly trying to figure out what&amp;rsquo;s going on, the author finally found that the error was occurring because of an user defined gradient clipping function that didn&amp;rsquo;t handle &lt;code&gt;IndexedSlices&lt;/code&gt; properly. The model involved embedding layers as it was dealing with machine translation task. Therefore, I thought of writing this blog with the hope that it would be of help to readers who are struggling to figure out what &lt;code&gt;IndexedSlices&lt;/code&gt; are.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tensorflow 2 code for Attention Mechanisms chapter of Dive into Deep Learning (D2L) book</title>
      <link>https://biswajitsahoo1111.github.io/post/tensorflow-2-code-for-attention-mechanisms-chapter-of-d2l-book/</link>
      <pubDate>Wed, 10 Mar 2021 00:00:00 +0000</pubDate>
      <guid>https://biswajitsahoo1111.github.io/post/tensorflow-2-code-for-attention-mechanisms-chapter-of-d2l-book/</guid>
      <description>&lt;table class=&#34;tfo-notebook-buttons&#34; align=&#34;left&#34;&gt;
  &lt;tr&gt;
  &lt;td align=&#34;left&#34;&gt;
    &lt;iframe src=&#34;https://ghbtns.com/github-btn.html?user=biswajitsahoo1111&amp;repo=D2L_Attention_Mechanisms_in_TF&amp;type=star&amp;count=true&amp;size=large&#34; frameborder=&#34;0&#34; scrolling=&#34;0&#34; width=&#34;170&#34; height=&#34;30&#34; title=&#34;GitHub&#34;&gt;&lt;/iframe&gt;
  &lt;/td&gt;
  &lt;!-----
  &lt;td align=&#34;left&#34; rowspan=&#34;2&#34;&gt;
    &lt;a href=&#34;https://biswajitsahoo1111.github.io/rul_codes_open/&#34;&gt;&lt;img src=&#34;https://www.tensorflow.org/images/GitHub-Mark-32px.png&#34; /&gt;View GitHub Page&lt;/a&gt;
  &lt;/td&gt;
  -----&gt;
  &lt;td align=&#34;left&#34; rowspan=&#34;2&#34;&gt;
    &lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF&#34;&gt;&lt;img src=&#34;https://www.tensorflow.org/images/GitHub-Mark-32px.png&#34; /&gt;View source on GitHub&lt;/a&gt;
  &lt;/td&gt;
  &lt;td align=&#34;left&#34; rowspan=&#34;2&#34;&gt;
    &lt;a href=&#34;https://codeload.github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/zip/master&#34;&gt;&lt;img src=&#34;https://www.tensorflow.org/images/download_logo_32px.png&#34; /&gt;Download code (.zip)&lt;/a&gt;
  &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
  &lt;td align=&#34;right&#34;&gt;  
    &lt;iframe src=&#34;https://ghbtns.com/github-btn.html?user=biswajitsahoo1111&amp;repo=D2L_Attention_Mechanisms_in_TF&amp;type=fork&amp;count=true&amp;size=small&#34; frameborder=&#34;0&#34; scrolling=&#34;0&#34; width=&#34;170&#34; height=&#34;30&#34; title=&#34;GitHub&#34; margin-left=&#34;auto&#34; margin-right=&#34;auto&#34;&gt;&lt;/iframe&gt;
  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;span style=&#34;color: purple;&#34;&gt;&lt;strong&gt;This code has been merged with D2L book. See PR: &lt;a href=&#34;https://github.com/d2l-ai/d2l-en/pull/1756&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1756&lt;/a&gt;, &lt;a href=&#34;https://github.com/d2l-ai/d2l-en/pull/1768&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;1768&lt;/a&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This post contains &lt;code&gt;Tensorflow 2&lt;/code&gt; code for Attention Mechanisms chapter of &lt;a href=&#34;http://d2l.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dive into Deep Learning (D2L)&lt;/a&gt; book. The chapter has 7 sections and code for each section can be found at the following links. We have given only code implementations. For theory, readers should refer the book.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_1_Visualization_of_attention.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.1. Attention Cues&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_2_Attention_based_regression.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.2. Attention Pooling: Nadaraya-Watson Kernel Regression&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_3_Attention_scoring_functions.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.3. Attention Scoring Functions&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_4_Bahdanau_attention.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.4. Bahdanau Attention&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_5_Multi-head_attention.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.5. Multi-Head Attention&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_6_Self-attention_and_positional_encoding.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.6. Self-Attention and Positional Encoding&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/10_7_Transformer.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10.7. Transformer&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;additional-sections&#34;&gt;Additional sections:&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF/blob/master/additional_sections/9_7_Sequence_to_Sequence_Learning.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;9.7. Sequence to Sequence Learning&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;additional-chapters&#34;&gt;Additional Chapters:&lt;/h3&gt;
&lt;p&gt;Chapter 17: &lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Generative_Adversarial_Networks_in_TF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;how-to-run-these-code&#34;&gt;How to run these code:&lt;/h3&gt;
&lt;p&gt;The best way (in our opinion) is to either clone the repo (or download the zipped repo) and then run each notebook from the cloned (or extracted) folder. All the notebooks will run without any issue.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: We claim no originality for the code. Credit goes to the authors of this excellent &lt;a href=&#34;http://d2l.ai/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;book&lt;/a&gt;. However, all errors and omissions are my own and readers are encouraged to bring it to my notice. Finally, no TF code was available (to the best of my knowledge) for &lt;code&gt;Attention Mechanisms&lt;/code&gt; chapter when &lt;a href=&#34;https://github.com/biswajitsahoo1111/D2L_Attention_Mechanisms_in_TF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;this repo&lt;/a&gt; was first made public.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
